<!DOCTYPE html>
<html lang="en">
<head>
  <title>Xun Xu, PhD</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="Xun Xu, Alex Xun Xu, Zero-Shot Learning, Transfer Learning, Action Recognition, Traffic Analysis, Anomaly Detection, Motion Segmentation, Deep Learning, Topic Model, Computer Vision, Machine Learning">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
</head>
<body>

<nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="#">Dr. Xun Xu</a>
    </div>
    <ul class="nav navbar-nav">
      <li class="active"><a href="#HOME">Home</a></li>
      <li><a href="#ABOUTME">About</a></li>
      <li><a href="#PEOPLE">People</a></li>
      <li><a href="#PUBLICATION">Publication</a></li>
    </ul>
  </div>
</nav>

<div class="container">

	<section id="HOME">
			<div class="page-header">
				<h2>Xun Xu<mdall> PhD B.Eng. </mdall></h2>
			</div>
			<div class="row">
			
				<div class="col-md-2">
					<div class="thumbnail">
						<img src="./img/XuXun_Corp2.jpg" class="img-rounded">
					</div>
				</div>
				
				
				<div class="col-md-3">
					<p>
						<strong>Scientist</strong>
					</p>
					<address>
						<a href="https://www.a-star.edu.sg/i2r" target="_blank">Institute for Infocomm Research (I2R)</a><br/>
						<a href="https://www.a-star.edu.sg/" target="_blank">A*STAR</a><br/>
						Level 13 Connexis (South Tower) </br>
						Singapore 138632 <br>
						E-mail: xux AT i2r.a-star.edu.sg
						<a href='https://scholar.google.com.sg/citations?user=pi0SGQUAAAAJ&hl=en' target="_blank"><span class='label label-primary'>Google Scholar</span></a>
						<a href='https://github.com/alex-xun-xu' target="_blank"><span class='label label-default'>GitHub</span></a>
						<a href='https://www.linkedin.com/in/xu-xun/' target="_blank"><span class='label label-info'>LinkedIn</span></a>
					</address>
				</div>
				
				<div class="col-md-7">
					<p>
						I am currently a senior scientist with the Institute for Infocomm Research (I2R), A-STAR. Prior to that, I was a Research Fellow working with <a href="https://www.comp.nus.edu.sg/~leegh/" target="_blank">Assist Prof. Lee Gim Hee</a> in the Computer Vision and Robotic Perception (CVRP) Lab of School of Computing, <a href="http://nus.edu.sg/" target="_blank">Natinoal University of Singapore</a> (NUS). I also worked with <a href="https://www.ece.nus.edu.sg/stfpage/eleclf/">Prof. Cheong Loong Fah</a> in Visual Interactive Media Lab of NUS from Sep 2016 to Mar 2019.
						I received a PhD degree from <a href="http://vision.eecs.qmul.ac.uk" target="_blank">Computer Vision Group</a> in the School of Electronic Engineering and Computer Science at <a href="http://www.qmul.ac.uk">Queen Mary, University of London</a> (QMUL), jointly supervised by <a href="http://www.eecs.qmul.ac.uk/~sgg/" target="_blank">Prof. Shaogang Gong</a> and <a href="http://www.eecs.qmul.ac.uk/~txiang/" target="_blank">Dr. Tao Xiang</a>. I was also working closely with <a href="http://homepages.inf.ed.ac.uk/thospeda/" target="_blank">Dr. Timothy Hospedales </a>.
					</p>
					<p>
						Before joining the Computer Vision Group in QMUL I received my B.Eng in Automation from <a href="http://www.scu.edu.cn" target="_blank">Sichuan University</a> and then had spent 2 years in <a href="#">3D Vision Lab</a> at Sichuan University supervised by <a href="mailto:yushengliu866@hotmail.com" target="_blank">Prof. Yusheng Liu</a> and <a href="http://www.linkedin.com/pub/kai-liu/16/285/a94" target="_blank">Prof. Kai Liu</a>.
					</p>
					<p>	My research interests include label-efficient learning and robust AI with applications to 3D point cloud data. 
					</p>
				</div>
			</div>
	</section>
</div>


<div class='container'>

	<section id='NEWS'>
			<div class="page-header">
				<h3>NEWS<mdall></mdall></h3>
			</div>
			<div class="row">
				<div class="col-md-12">
					<h4><b>Openings</b></h4>
					<b>TOP</b>: We are always looking for highly self-motivated students. Please feel free to contact me if you wish to consider the following opportunities<br>
- <b>Short-term internship</b> with paid allowance & eligible to non-Singaporean undergrad and master students.<br>
- <b>Visiting PhD/Master/Ungrad</b> funded by <a href='https://www.csc.edu.cn/' target="_blank"><b>CSC</b></a>, <a href='https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme' target="_blank"><b>ARAP</b></a> and <a href='https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies/singapore-international-pre-graduate-award-sipga' target="_blank"><b>SIPGA</b></a> scholarships are available. <br>
- <b>Pursuing PhD</b> with Singapore universities and A*STAR funded by <a href='https://www.a-star.edu.sg/Scholarships/for-graduate-studies/singapore-international-graduate-award-singa' target="_blank"><b>SINGA</b></a> or <a href='https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme' target="_blank"><b>ARAP</b></a> scholarship.<br> 
<!--<font style="background-color:Tomato;color:White;">Find more details for eligible <a href="./Ad/Scholarships_2023.html">scholarships</a></font><br>-->
- Find more details for eligible <a href="./Ad/Scholarships_2023.html" target="_blank"><b>scholarships</b></a><br>
- Find details for the above scholarships in a single <a href="./Ad/ASTAR_Scholarship_ICCV23.pdf" target="_blank"><b>PDF</b></a>

<!-- 12nd May 2023: <font style="background-color:Tomato;color:White;">OPENING (DDL: open until filled)</font>: One full-time <b>research scientist</b> position on developing robust 3D deep learning algorithms is available with <a href='https://www.linkedin.com/jobs/view/3599956806/' target="_blank">details</a>. Please contact me for informal inquiries.<br> -->

					<h4><b>Research</b></h4>
					<h5><b>Projects</b></h5>
					- May 2023: <b>A*STAR MTC Programmatic Fund "Towards Realistic Deep Learning for 3D Vision" (SGD$ 1.1M allocated) will kickstart in Aug 2023</b><br>
<ul>
<li> We shall develop 3D deep learning techniques robust to imperfect visibility, adversarial attacks and incremental data to enable deployment in real-world applications.<br>
</ul>	
- May 2021: <b>A*STAR CDA Project "Exploiting Unlabeled Data, Cheaper Labels and Efficient Annotation for 3D 
Point Cloud Deep Learning" (EUDEA) ($SGD 238k allocated)</b>
					<ul>
					<li> My project on exploring label-efficient learning on 3D point cloud data started from Apr. 2021.<br>
					<li> We will be looking into improving the efficiency of 3D point cloud learning from several perspectives.<br>
					</ul>
					<h5><b>Publications</b></h5>
- Dec 2023: We are happy to share our most recent work on <b>improving the generalization of Segment Anything model</b> - <a href="https://github.com/zhang-haojie/wesam"><b>WeSAM</b></a> <br>
- Nov 2023: Our work on <a href="#LiuEtAl_TGRS23">Transformation-Invariant Network for Few-Shot Object Detection in Remote Sensing Images</b></a> was accepted by <b>IEEE Transactions on Geoscience and Remote Sensing</b>. Congratulations to <a href="https://scholar.google.com/citations?user=x3dCJrAAAAAJ&hl=en" target="_blank">Nanqing Liu</a>! <br>	
- Oct 2023: Our work on <a href="#XuEtAl_NeuroComputing23">Revisiting Pretraining for Semi-Supervised Learning in the Low-Label Regime</b></a> was accepted by <b>Neurocomputing</b>. Congratulations! <br>				
- Jul 2023: Our work on <a href="#LiEtAl_ICCV23">On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion</b></a> was accepted by <b>ICCV 2023 as Oral presentation (1.8% acceptance rate)</b>. Congratulations to <a href="https://yushu-li.github.io/">Yushu Li</a>!<br>
- May 2023: Our work on <a href="#SuEtAl_TCSVT23">Weakly Supervised 3D Point Cloud Segmentation via Multi-Prototype Learning</b></a> was accepted by <b>IEEE Transactions on Circuits and System for Video Technology (TCSVT)</b>. Congratulations to <a href="https://yysu.site/">Yongyi Su</a>!<br>
- Jan 2023: Our work on <a href="#NguyenEtAl_ML23">Diverse and consistent multi-view networks for semi-supervised regression</b></a> was accepted by <b>ECML PKDD Journal Track 2023</b>.<br>
- Sep 2022: Our work on <a href="#SuEtAl_NeurIPS22">Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering</b></a> was accepted by <b>NeurIPS 2022</b>. Congratulations to <a href="https://yysu.site/" target="_blank">Su Yongyi</a>!<br>
- Jun 2022: Our work on <b>Open-Set Semi-Supervised Learning for 3D Point Cloud Understanding</b> was accepted by <b>ICPR 2022</b> as Oral presentation.<br>
- May 2022: Our work on <a href="#XuEtAl_TIP22">SemiCurv: Semi-Supervised Curvilinear Structure Segmentation</b></a> was accepted by <b>IEEE Transactions on Image Processing (TIP)</b>.<br>
- May 2022: Our work on <a href="#JiangEtAl_TIP22">MA-GANet: A Multi-Attention Generative Adversarial Network for Defocus Blur Detection</b></a> was accepted by <b>IEEE Transactions on Image Processing (TIP)</b>.<br>
- Nov 2021: Our work on <b>Automatic Data Augmentation for 3D Point Cloud</b> has appeared in BMVC 2021</b>. Code is available <a href="https://github.com/RosettaWYzhang/AdaPC" target="_blank">here</a>.<br>
- Jun 2021: The first 3D affordance prediction dataset <a href="#DengEtAl_CVPR21">3D AffordanceNet: A Benchmark for Visual Object Affordance Understanding</b></a> has appeared in <b>CVPR 2021</b>. Code is available <a href="https://andlollipopde.github.io/3D-AffordanceNet" target="_blank">here</a>.<br>
- Mar 2021: Our work on <a href="#XuEtAl_TCSVT21">Learning Clustering for Motion Segmentation</b></a> has appeared in <b>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</b>.

					<!-- 
					<h4></h4>
					Jul 2021: <b>PostDoc Fellowship Opportunities</b><br>
					<li> You will have a chance to carry out postdoc research in A*STAR with competitive fellowship if you are ASEAN citizenship. More details can be found at <a href="https://snas.org.sg/aseanfellowship" target="_blank">check your availibity</a>. Please contact if you are qualified and interested. Deadline is 30 Nov 2021. 
					-->
					<h4></h4>
					
				</div>
			
				<!-- <div class="col-md-12">
					<h4></h4>
					Nov 2020: <b>PhD/Postgraduate/Undergraduate Scholarship Opportunities</b><br>
					<ul>
					<li> We are looking for highly motivated international students who wish to do PhD in A*STAR, NUS, NTU, SUTD. We provide <b>full scholarship under the SINGA program</b> (<a href='https://www.a-star.edu.sg/Scholarships/for-graduate-studies/singapore-international-graduate-award-singa' target="_blank">check your eligibility</a>).<br>
					<li> We also welcome international full-time PhD students who wish to do research attachment (1-2 years research with A*STAR). <b>Full scholarship under the ARAP program</b> will be provided during the attachment period in Singapore (<a href='https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme-(arap)' target="_blank">Check your eligibility</a>)<br>
					<li> We provide scholarship for talented postgraduate/undergraduate students who wish to do research attachment (2-6 months with A*STAR) or prepare to apply for PhD under the SIPGA program (<a href='https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies/singapore-international-pre-graduate-award-(sipga)' target="_blank">Check your availability</a>).
					</ul>
				</div> -->
			</div>
		</section>
	
	</section>

</div>


<div class='container'>

	<section id='ABOUTME'>
			<div class="page-header">
				<h3>About Me<mdall></mdall></h3>
			</div>
			<div class="row">
				<div class="col-md-4">
					<h4>Education Background</h4>
					<ul>
						<li>PhD in Computer Science, Queen Mary University of London, 2016<br>
							Thesis: <a href="https://www.dropbox.com/s/zc4m6yvjh49t6wu/Xu_Thesis_Final.pdf?dl=0" target="_blank">Semantic Spaces for Video Analysis of Behaviour</a> <br>
							Supervisors: Prof. Shaogang Gong and Dr. Tao Xiang
						<li>M.Sc in Control Theory and Engineering, Sichuan University, 2012<br>
							Supervisor: Prof. Yusheng Liu
						<li>B.Eng in Automation, Sichuan University, 2010<br>
						
					</ul>
				</div>
				<div class="col-md-4">
					<h4>Professional Experience</h4>
					<ul>
						<li>Scientist with I2R, A-STAR, Singpaore<br>
							2019.12-Now<br>
						<li>Research Fellow in SoC, National University of Singapore<br>
							2019.4-2019.12<br>
							Supervisors: Prof. Gim Hee Lee
						<li>Research Fellow in ECE, National University of Singapore<br>
							2016.9-2019.3<br>
							Supervisors: Prof. Loong-Fah Cheong
					</ul>
				</div>
				
				<div class="col-md-4">
					<h4>Academic Services</h4>
						<h5><b>Member</b></h5>
						<ul>
							<li>IEEE Senior Member</li>
						</ul>
						<h5><b>Journal Reviewer</b></h5>
						<ul>
							<li> IJCV, TIP, TNNLS, TMLR, TCSVT, etc. </li>
							<!--  <li> Transactions on Machine Learning Research (TMLR) </li>
							<li> IEEE Transactions on Image Processing (TIP)</li>
							<li> IEEE Transactions on Neural Networks and Learning Systems (TNNLS) </li>
							<li> ACM Transactions on Knowledge Discovery from Data (TKDD)</li>
							<li> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li> -->

							
						</ul>
						<h5><b>Conference Reviewer</b></h5>
						<ul>
							<li> NeurIPS, ICLR, ICML, CVPR, ECCV, ICCV, etc. </li>
							<!--  <li>  </li>
							<li> ICML </li>
							<li> CVPR</li>
							<li> ECCV </li>
							<li> ICCV </li> -->
						</ul>
				</div>
			</div>
		</section>
	
	</section>

</div>

<div class='container'>

	<section id='PEOPLE'>
		<div class="page-header">
			<h3>People<mdall></mdall></h3>
		</div>
		
		<div>
			<h4>Staffs</h4>
			<ul>
			<li><a href="https://scholar.google.co.uk/citations?user=XKupj84AAAAJ&hl=en" target="_blank">Dr. Adam Goodge</a> (Research Scientist, Co-RO)</a></li>
			<li><a href="https://www.linkedin.com/in/jingyi-liao-bb2217164/?originalSubdomain=sg" target="_blank">Ms. Jingyi Liao</a> (Research Engineer, Co-RO)</a></li>
			</ul>
			<h4>Students</h4>
			<ul>
			<li><a href="https://yysu.site/" target="_blank">Mr. Yongyi Su</a> (Visiting PhD Student from South China University of Technology)</li>
			<li><a href="https://scholar.google.com/citations?user=x3dCJrAAAAAJ&hl=en" target="_blank">Mr. Nanqing Liu</a> (Visiting PhD Student from Southwest Jiaotong University)</li>
			<li><a href="https://cxliu0.github.io/" target="_blank">Mr. Chengxin Liu</a> (Visiting PhD Student from Huazhong University of Science and Technology)</li>
			<li><a href="https://yushu-li.github.io/" target="_blank">Mr. Yushu Li</a> (SIPGA funded Master Student from South China University of Technology)</li>
			</ul>
			<h4>Past Members</h4>
			<ul>
			<li>Mr. Rong Pang (Visiting PhD Student from Southwest Jiaotong University, 2023.03-2023.12, Now pursuing PhD at Southwest Jiaotong University)</li>
			<li><a href="https://rosettawyzhang.github.io/" target="_blank">Ms. Wanyue Zhang</a> (Research Engineer Co-RO, 2020.09-2021.09, Now pursing PhD at Max Planck Institute for Informatics)</li>
			</ul>
		</div>
</div>


<div class='container'>

	<section id='PUBLICATION'>
	
		<div class="page-header">
			<h3>Selected Publications<mdall></mdall></h3>
		</div>
			
		Visit my <a href='https://scholar.google.com.sg/citations?user=pi0SGQUAAAAJ&hl=en' target="_blank"><span class='label label-primary'>Google Scholar</span></a>
 for a complete list of publications 

		<h4>2024</h4>
		
		<div class="row" id="ZhangEtAl_CVPR24">
			<div class="col-md-3"><img src="./img/ZhangEtAl_CVPR24.png" width="220" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Improving the Generalization of Segmentation Foundation Model under Distribution Shift via Weakly Supervised Adaptation</strong></span>
				<a href="https://arxiv.org/abs/2312.03502"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/zhang-haojie/wesam" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<!-- <a href="./Doc/Publication/2023/LiEtAl_ICCV23.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Haojie Zhang, Yongyi Su, <b>Xun Xu</b>, and Kui Jia<br>
					Preprint</span>
			</div>
		</div>
		<br>

		<h4>2023</h4>

		<div class="row" id="LiEtAl_ICCV23">
			<div class="col-md-3"><img src="./img/LiEtAl_ICCV23.png" width="220" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion</strong></span>
				<a href="https://arxiv.org/abs/2308.09942"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://yushu-li.github.io/owttt-site/" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2023/LiEtAl_ICCV23.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Yushu Li, <b>Xun Xu</b>, Yongyi Su and Kui Jia<br>
					IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023 (<b>Oral Presentation</b> 1.8% acceptance rate)</span>
			</div>
		</div>
		<br>

		<div class="row" id="XuEtAl_NeuroComputing23">
			<div class="col-md-3"><img src="./img/XuEtAl_TNNLS22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Revisiting Pretraining for Semi-Supervised Learning in the Low-Label Regime</strong></span>
				<a href="https://arxiv.org/abs/2205.03001"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details"><b>Xun Xu</b>, Jingyi Liao, Lile Cai, Manh Cuong Nguyen, Kangkang Lu, Wanyue Zhang, Yasin Yazici and Chuan Sheng Foo<br>
					<b>Neurocomputing</b>, 2023 </span>
			</div>
		</div>
		<br>
		
		<div class="row" id="SuEtAl_TCSVT23">
			<div class="col-md-3"><img src="./img/SuEtAl_TCSVT23.png" width="220" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Weakly Supervised 3D Point Cloud Segmentation via Multi-Prototype Learning</strong></span>
				<a href="https://arxiv.org/abs/2205.03137"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2023/SuEtAl_TCSVT23.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Yongyi Su, <b>Xun Xu</b> and Kui Jia<br>
					IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2023 </span>
			</div>
		</div>
		<br>

		<div class="row" id="LiuEtAl_TGRS23">
			<div class="col-md-3"><img src="./img/LiuEtAl_TGRS23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Transformation-Invariant Network for Few-Shot Object Detection in Remote Sensing Images</strong></span>
				<a href="https://arxiv.org/abs/2303.06817"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Nanqing Liu, <b>Xun Xu</b>, Turgay Celik, Zongxin Gan and Heng-Chao Li<br>
					IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), 2023 </span>
			</div>
		</div>
		<br>



		<div class="row" id="NguyenEtAl_ML23">
			<div class="col-md-3"><img src="./img/NguyenEtAl_ML23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Diverse and consistent multi-view networks for semi-supervised regression</strong></span>
				<a href="https://openreview.net/pdf?id=J9_7t9m8xRj"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Cuong Nguyen, Arun Raja, Le Zhang, <b>Xun Xu</b>, Balagopal Unnikrishnan, Mohamed Ragab, Kangkang Lu and Chuan-Sheng Foo<br>
					Machine Learning (<b>ML</b>), 2023 </span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/LuEtAl_ICASSP23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>On Adversarial Robustness of Audio Classifiers</strong></span>
				<a href=""  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!--<a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Kangkang Lu, Manh Cuong Nguyen, <b>Xun Xu</b> and Chuan Sheng Foo
					  International Conference on Acoustics, Speech, & Signal Processing (<b>ICASSP 2023</b>) </span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/SuEtAl_TRIBE23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Towards Real-World Test-Time Adaptation: Tri-Net Self-Training with Balanced Normalization</strong></span>
				<a href="https://arxiv.org/pdf/2309.14949.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/Gorilla-Lab-SCUT/TRIBE" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Yongyi Su, <b>Xun Xu</b> and Kui Jia<br>
					Preprint, 2023 </span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/LiuEtAl_OSSOD23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Semi-Supervised Object Detection with Uncurated Unlabeled Data for Remote Sensing Images</strong></span>
				<a href="https://arxiv.org/pdf/2310.05498.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TRIBE" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Nanqing Liu, <b>Xun Xu</b>, Yingjie Gao and Heng-Chao Li<br>
					Preprint, 2023 </span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/SuEtAl_TPAMI23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering Regularized Self-Training</strong></span>
				<a href="https://arxiv.org/abs/2303.10856"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Yongyi Su, <b>Xun Xu</b>, Tianrui Li and Kui Jia<br>
					Preprint, 2023 </span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/ChenEtAl_ICCV23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>STFAR: Improving Object Detection Robustness at Test-Time by Self-Training with Feature Alignment Regularization</strong></span>
				<a href="https://arxiv.org/abs/2303.17937"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Yijin Chen, <b>Xun Xu</b>, Yongyi Su, Kui Jia<br>
					Preprint, 2023 </span>
			</div>
		</div>
		<br>

		


		<h4>2022</h4>

		<div class="row" id="SuEtAl_NeurIPS22">
			<div class="col-md-3"><img src="./img/SuEtAl_NeurIPS22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering</strong></span>
				<a href="https://arxiv.org/abs/2206.02721"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Yongyi Su, <b>Xun Xu</b> and Kui Jia<br>
					Advances in Neural Information Processing Systems (<b>NeurIPS 2022</b>) </span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/XuEtAl_TIP22.png" width="250" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>SemiCurv: Semi-Supervised Curvilinear Structure Segmentation</strong></span>
				<a href="https://arxiv.org/abs/2205.08706"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/alex-xun-xu/SemiCurv" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2022/XuEtAl_TIP22.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details"><b>Xun Xu</b>, Manh Cuong Nguyen, Yasin Yazici, Kangkang Lu, Hlaing Min, Chuan Sheng Foo<br>
					IEEE Transactions on Image Processing (<b>TIP</b>), 2022 </span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/JiangEtAl_TIP22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>MA-GANet: A Multi-Attention Generative Adversarial Network for Defocus Blur Detection</strong></span>
				<a href="./Doc/Publication/2022/JiangEtAl_TIP22.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Zeyu Jiang, <b>Xun Xu</b>, Le Zhang, Chao Zhang, Chuan Sheng Foo and Ce Zhu<br>
					IEEE Transactions on Image Processing (<b>TIP</b>), 2022 </span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/ShiEtAl_ICPR22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Open-Set Semi-Supervised Learning for 3D Point Cloud Understanding</strong></span>
				<a href="https://arxiv.org/abs/2205.01006"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2022/ShiEtAl_ICPR22.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Xian Shi, <b>Xun Xu</b>, Wanyue Zhang, Xiatian Zhu, Chuan Sheng Foo and Kui Jia<br>
					International Conference on Pattern Recognition (<b>ICPR 2022</b>) (Oral Presentation)</span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/JoshiEtAl_TNNLS21.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>On Representation Knowledge Distillation for Graph Neural Networks</strong></span>
				<a href="https://arxiv.org/abs/2111.04964"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2022/ChaitanyaEtAl_TNNLS22.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Chaitanya K. Joshi, Fayao Liu, <b>Xun Xu</b>, Jie Lin and Chuan Sheng Foo<br>
					IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>), 2022 </span>
			</div>
		</div>
		<br>

		


		
		<div class="row">
			<div class="col-md-3"><img src="./img/LiangEtAl_TITS22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Exploring Diversity-based Active Learning for 3D Object Detection in Autonomous Driving</strong></span>
				<a href="https://arxiv.org/abs/2205.07708"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Zhihao Liang, <b>Xun Xu</b>, Shengheng Deng, Lile Cai, Tao Jiang and Kui Jia<br>
					Preprint, 2022 </span>
			</div>
		</div>
		<br>


		
		<h4>2021</h4>


		<div class="row" id="XuEtAl_TCSVT21">
			<div class="col-md-3"><img src="./img/XuEtAl_TCSVT2021.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Learning Clustering for Motion Segmentation</strong></span>
				<a href="./Doc/Publication/2021/XuEtAl_TCSVT21.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="https://github.com/alex-xun-xu/LearnSubspaceMoSeg" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2021/XuEtAl_TCSVT21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details"><b>Xun Xu</b>, Loong-Fah Cheong, Zhuwen Li, Le Zhang and Ce Zhu<br>
					IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2021</span>
			</div>
		</div>
		<br>


		<div class="row" id="DengEtAl_CVPR2021">
			<div class="col-md-3"><img src="./img/DengEtAl_CVPR2021.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>3D AffordanceNet: A Benchmark for Visual Object Affordance Understanding</strong></span>
				<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_3D_AffordanceNet_A_Benchmark_for_Visual_Object_Affordance_Understanding_CVPR_2021_paper.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://andlollipopde.github.io/3D-AffordanceNet/#/" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2021/DengEtAl_CVPR21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Shengheng Deng <b>Xun Xu</b>, Chaozheng Wu, Ke Chen and Kui Jia<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2021</b>) </span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/CaiEtAl_CVPR2021.png" width="200" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Revisiting Superpixels for Active Learning in Semantic Segmentation with Realistic Annotation Costs</strong></span>
				<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cai_Revisiting_Superpixels_for_Active_Learning_in_Semantic_Segmentation_With_Realistic_CVPR_2021_paper.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="./Doc/Publication/2021/CaiEtAl_CVPR21_Supp.pdf"  target="_blank"><span class="label label-default">Supplementary</span></a>
				<a href="https://github.com/cailile/Revisiting-Superpixels-for-Active-Learning" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2020/CaiEtAl_CVPR21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Lile Cai, <b>Xun Xu</b>, Junhao Lieuw and Chuan Sheng Foo<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2021</b>)</span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/LuEtAl_ICLR2021.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>ARMOURED: Adversarially Robust MOdels using Unlabeled data by REgularizing Diversity</strong></span>
				<a href="https://openreview.net/forum?id=JoCR4h9O3Ew"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2021/LuEtAl_ICLR21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Kangkang Lu, Cuong M Nguyen, <b>Xun Xu</b>, Kiran Chari, Yu Jing Goh and Chuan Sheng Foo<br>
					International Conference on Learning Representations (<b>ICLR 2021</b>)</span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/CaiEtAl_TIP21.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Exploring Spatial Diversity for Region-based Active Learning</strong></span>
				<a href=""  target="./Doc/Publication/2021/CaiEtAl_TIP21.pdf"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Lile Cai, <b>Xun Xu</b>, Lining Zhang and Chuan Sheng Foo<br>
					IEEE Transactions on Image Processing (<b>TIP</b>), 2021</span>
			</div>
		</div>
		<br>


		<div class="row">
                        <div class="col-md-3"><img src="./img/ZhangEtAl_BMVC21.png" width="280" style="border-style: none">
                        </div>
                        <div class="col-md-9">
                                <span class="title"><strong>On Automatic Data Augmentation for 3DPoint Cloud Classification</strong></span>
                                <a href="https://www.bmvc2021-virtualconference.com/assets/papers/0911.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
                                <a href="https://github.com/RosettaWYzhang/AdaPC" target="_blank"><span class="label label-success" >ProjectPage</span></a>
                                <a href="./Doc/Publication/2021/ZhangEtAl_BMVC21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
                                <br>
                                <span class="details">Wanyue Zhang, <b>Xun Xu</b>, Fayao Liu, Le Zhang and Chuan Sheng Foo<br>
                                        British Machine Vision Conference (<b>BMVC 2021</b>)</span>
                        </div>
                </div>
                <br>


		<div class="row">
			<div class="col-md-3"><img src="./img/Shi_EtAl_ActivePC.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Label-Efficient Point Cloud Semantic Segmentation: An Active Learning Approach</strong></span>
				<a href="https://arxiv.org/abs/2101.06931"  target="_blank"><span class="label label-default">PDF</span></a>
				<!--<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>-->
				<!--<a href="./Doc/Publication/2020/LuEtAl_ICLR2021.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>-->
				<br>
				<span class="details">Xian Shi, <b>Xun Xu</b>, Ke Chen, Lile Cai, Chuan Sheng Foo and Kui Jia<br>
					Preprint, 2021</span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/WuEtAl_ShapeSaliency.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Learning Category-level Shape Saliency via Deep Implicit Surface Networks</strong></span>
				<a href="https://arxiv.org/abs/2012.07290"  target="_blank"><span class="label label-default">PDF</span></a>
				<!--<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>-->
				<!--<a href="./Doc/Publication/2020/LuEtAl_ICLR2021.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>-->
				<br>
				<span class="details">Chaozheng Wu, Sun Lin, <b>Xun Xu</b> and Kui Jia<br>
					Preprint, 2021</span>
			</div>
		</div>
		<br>

		<h4>2020</h4>
		<div class="row">
			<div class="col-md-3"><img src="./img/JiangXZLZ_MMSP20.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>MultiANet: a Multi-Attention Network for DefocusBlur Detection</strong></span>
				<a href="./Doc/Publication/2020/JiangXZZ_MMSP20.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2020/JiangXZZ_MMSP20.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Zeyu Jiang, <b>Xun Xu</b>, Chao Zhang, Xiaoning Liu and Ce Zhu<br>
					IEEE International Workshop on Multimedia Signal Processing (<b>MMSP 2020</b>)</span>
			</div>

		</div>
		<br>

		
		<div class="row">
                        <div class="col-md-3"><img src="./img/XuL_CVPR20_Thumbnail.png" width="280" style="border-style: none">
                        </div>
                        <div class="col-md-9">
                                <span class="title"><strong>Weakly Supervised Semantic Point Cloud Segmentation: Towards 10× Fewer
Labels</strong></span>
                                <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Weakly_Supervised_Semantic_Point_Cloud_Segmentation_Towards_10x_Fewer_Labels_CVPR_2020_paper.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
                                <a href="https://github.com/alex-xun-xu/WeakSupPointCloudSeg" target="_blank"><span class="label label-success" >ProjectPage</span></a>
                                <a href="./Doc/Publication/2020/XuL_CVPR20.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
                                <br>
                                <span class="details"><b>Xun Xu</b> and Gim Hee Lee<br>
                                        IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2020</b>)</span>
                        </div>

                </div>
		<br>
		
		<h4>2019</h4>
		<div class="row">

			<div class="col-md-3"><img src="./img/XuCL_TPAMI19_Thumbnail.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>3D Rigid Motion Segmentation with Mixed and
Unknown Number of Models</strong></span>
				<a href="./Doc/Publication/2019/XuCL_TPAMI19.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="./ProjectPage/CVPR_18/index.html" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2019/XuCL_TPAMI19.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details"><b>Xun Xu</b>， Loong-Fah Cheong and Zhuwen Li<br>
					IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2019</span>
			</div>
		</div>
		<br>
		
		<div class="row">
		
			<div class="col-md-3"><img src="./img/ZLXZ_CVPR19.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> C3AE: Exploring the Limits of Compact Model for Age Estimation</strong></span>
				<a href="https://arxiv.org/abs/1904.05059"  target="_blank"><span class="label label-default">PDF</span></a><br>
				<span class="details">Chao Zhang, Shuaicheng Liu, <b>Xun Xu</b> and Ce Zhu<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2019</b>) </span>
			</div>
		</div>
		<br>

		<!-- <div class='row'>
			<div class="col-md-3"><img src="./img/XuCL_CVPR19_Thumbnail.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong> Learning for Multi-Model and Multi-Type Fitting </strong></span>
				<a href="https://arxiv.org/abs/1901.10254"  target="_blank"><span class="label label-default">ArXiv</span></a><br>
				<span class="details"><b>Xun Xu</b>, Loong-Fah Cheong and Zhuwen Li<br>
					ArXiv:1901.10254, 2019 </span>
			</div>
		</div> -->  
		
		<h4>2018</h4>
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuCL_CVPR18_Thumbnail.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Motion Segmentation by Exploiting Complementary Geometric Models </strong></span>
				<a href="./Doc/Publication/2018/XuCL_CVPR18.pdf"  target="_blank"><span class="label label-default">PDF</span></a> <a href="./ProjectPage/CVPR_18/index.html" target="_blank"><span class="label label-success" >ProjectPage</span></a> <a href="./Doc/Publication/2018/XuCL_CVPR18.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details"><b>Xun Xu</b>, Loong-Fah Cheong and Zhuwen Li<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2018</b>) </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/LinJCLX_ACCV18.png" width="280" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Robust Video Background Identification by Dominant Rigid Motion Estimation</strong></span>
				<a href="./Doc/Publication/2018/LinJCLX_ACCV2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/LinJCLX_ACCV2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details">Kaimo Lin, Nianjuan Jiang, Loong Fah Cheong, Jiangbo Lu and <b>Xun Xu</b><br>
				Asian Conference on Computer Vision (<b>ACCV 2018</b>) </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/ZhangZXXL_ICME18.png" width="190" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Image Ordinal Classification and Understanding: Grid Dropout with Mask Label</strong></span>
				<a href="./Doc/Publication/2018/ZhangZXXL_ICME2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/ZhangZXXL_ICME2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a>  <b>[Oral Presentation]</b><br>
				<span class="details">Chao Zhang, Ce Zhu, Jimin Xiao, <b>Xun Xu</b> and Yipeng Liu<br>
				IEEE Conference on Multimedia and Expo (<b>ICME 2018</b>) </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/ZhangZXXLT_SPIC18.png" width="200" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Visual aesthetic understanding: Sample-specific aesthetic classification and deep activation map visualization</strong></span>
				<a href="./Doc/Publication/2018/ZhangZXXLT_SPIC2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/ZhangZXXLT_SPIC2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details">Chao Zhang, Ce Zhu, <b>Xun Xu</b>, Yipeng Liu, Jimin Xiao and Tammam Tillo<br>
				Signal Processing: Image Communication (<b>SPIG</b>), 2018 </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/ZhangXZ_EL18.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Image ordinal classification with deep multi-view learning</strong></span>
				<a href="./Doc/Publication/2018/ZhangXZ_EL2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/ZhangXZ_EL2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details">Chao Zhang,  <b>Xun Xu</b> and Ce Zhu<br>
				Electronic Letters, 2018 </span>
			</div>
		</div>
		
		
		<h4>2017</h4>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_IJCV17.png" width="260" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Transductive Zero-Shot Action Recognition by Word-Vector Embedding</strong></span>
				<a href="./Doc/Publication/2017/XuHG_IJCV2017.pdf"><span class="label label-default">PDF</span></a> <a href="./ProjectPage/IJCV_17/Readme.txt" target="_blank"><span class="label label-success" >Data</span></a> <a href="./Doc/Publication/2017/XuHG_IJCV17.txt" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				International Journal of Computer Vision (<b>IJCV</b>), 2017 </span>
			</div>
		</div>
		<br>
		
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_TCSVT15.png" width="240" style="border-style: none">
			</div>
			
		
			<div class="col-md-9">
				<span class='title'><strong>Discovery of Shared Semantic Spaces for Multi-Scene Video Query and Summarization</strong></span> <a href="./Doc/Publication/2015/XuHG_TCSVT2015.pdf"><span class="label label-default">PDF</span></a>  <a href="./Doc/Publication/2015/XuHG_TCSVT2015_Supp.pdf"><span class="label label-default">Supplementary</span></a>  <a href="./ProjectPage/TCSVT_15/data/MultiScene.pdf"><span class="label label-success">Slides</a> <a href="./ProjectPage/TCSVT_15/index.html"><span class="label label-success">Project Page</span></a> <a href="./Doc/Publication/2017/XuHG_TCSVT17.txt" target="_blank"><span class="label label-default">Bibtex</span></a> <b></b> <br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2017</span>
			</div>
		</div>
		<br>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuGH_ZSLCrowdBehaviour17.png" width="260" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Zero-Shot Crowd Behaviour Recognition</strong></span>
				<a href="./Doc/Publication/2017/XuGH_ZSLCrowdBehaviour2017.pdf"><span class="label label-default">PDF</span></a> <br>
				<span class="details"><b>Xun Xu</b>, Shaogang Gong and Timothy Hospedales<br>
				In Murino, Shah, Cristani, Savarese (Eds.), <a href="https://www.elsevier.com/books/group-and-crowd-behavior-for-computer-vision/murino/978-0-12-809276-7">Group and Crowd Behaviour Understanding in Computer Vision </a>, Elsevier, April 2017. </span>
			</div>
		</div>
		
		<br>
		
		
		<h4>2016</h4>
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_ECCV16.png" width="260" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>Multi-Task Zero-Shot Action Recognition with Prioritised Data Augmentation</strong></span>
				<a href="./Doc/Publication/2016/XuHG_ECCV2016.pdf"><span class="label label-default">PDF</span></a> <a href="./ProjectPage/IJCV_17/Readme.txt" target="_blank"><span class="label label-success" >Data</span></a> <a href="./Doc/Publication/2016/XuHG_ECCV16.txt" target="_blank"><span class="label label-default">Bibtex</span></a> <br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				European Conference on Computer Vision (<b>ECCV 2016</b>) </span>
			</div>
		</div>
		
		<h4>2015</h4>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_ICIP15.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>Semantic Embedding Space for Zero ­Shot Action Recognition</strong></span>
				<a href="./Doc/Publication/2015/XuHG_ICIP2015.pdf"><span class="label label-default">PDF</span></a> <a href="http://www.eecs.qmul.ac.uk/~xx302/Doc/Publication/2015/XuHG_ICIP2015_Slides.pptx"><span class="label label-success">Slides</span></a> <a href="./ProjectPage/ICIP_15/Demo.tar.gz"><span class="label label-success">Demo</span></a> <a href="./ProjectPage/ICIP_15/XuHG_ICIP15.bib"><span class="label label-default">Bibtex</span></a> <b>[★ recognized as top 10% papers]</b> <br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				International Conference on Image Processing (<b>ICIP 2015</b>) </span>
			</div>
		</div>
		
		<h4>2013</h4>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuGH_ACMMM_ARTEMIS13.png" width="230" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>Cross-Domain Traffic Scene Understanding by Motion Model Transfer</strong></span> 
				<a href="./Doc/Publication/2013/XuGH_ACMMM_ARTEMIS2013.pdf"><span clsudo nvidia-smi -pm 1
ass="label label-default">PDF</span></a>
				<a href="./Doc/Publication/2013/Artemix13_XuGH_Demo_ver1.0.7z"><span class="label label-default">Code</span></a> <a href="./Doc/Publication/2013/XuGH_ACMMM_ARTEMIS2013.bib"><span class="label label-default">Bibtex</span></a> </br>
				<span class="details"><b>Xun Xu</b>, Shaogang Gong and Timothy Hospedales</br>
				ACM International Conference on Multimedia,
					Workshop on Analysis and Retrieval of Tracked Events and Motion in Imagery Streams</i>, 2013 </span>
			</div>
		</div>
		
	</section>

</div>

<br>
<br>
<br>




<div class="container">
	<p class="pull-right"><a href="#HOME">Back to top</a></p>
	<p><small>Updated Dec 2023</small></p>
	<!-- <p><small>Page created using <a href="http://twitter.github.com/bootstrap" target="_blank">bootstrap</a></small></p> -->
</div>

</body>
</html>
