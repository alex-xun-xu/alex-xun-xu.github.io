<!DOCTYPE html>
<html lang="en">
<head>
  <title>Xun Xu, PhD, Senior Scientist</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="Xun Xu, Alex Xun Xu, Zero-Shot Learning, Transfer Learning, Action Recognition, Traffic Analysis, Anomaly Detection, Motion Segmentation, Deep Learning, Topic Model, Computer Vision, Machine Learning">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
  
    <style>
    /* Style the collapsible container */
    .collapsible-list {
      max-height: 350px; /* Limit the height for collapsed state */
      max-width: 1200px; /* Limit the width of the container */
      width: 100%; /* Make it responsive (optional) */
      overflow: hidden; /* Hide items that exceed the height */
      transition: max-height 0.3s ease; /* Smooth animation for collapsing/expanding */
      border: 1px solid #ccc; /* Optional: Add a border */
      padding: 10px;
      box-sizing: border-box; /* Include padding in width calculations */
    }
    .collapsible-list ul {
      list-style-type: none;
      padding: 0;
      margin: 0;
    }
    .collapsible-list li {
      padding: 5px;
      border-bottom: 1px solid #ddd; /* Optional divider */
    }
    .toggle-button {
      margin-top: 10px;
      padding: 5px 10px;
      background-color: #007bff;
      color: #fff;
      border: none;
      cursor: pointer;
      border-radius: 5px;
    }
    .toggle-button:hover {
      background-color: #0056b3;
    }
  </style>
  
  
</head>



<body>

<nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="#">Dr. Xun Xu</a>
    </div>
    <ul class="nav navbar-nav">
      <li class="active"><a href="#HOME">Home</a></li>
      <li><a href="#ABOUTME">About</a></li>
      <li><a href="#PEOPLE">People</a></li>
      <li><a href="#PUBLICATION">Publication</a></li>
    </ul>
  </div>
</nav>

<div class="container">

	<section id="HOME">
			<div class="page-header">
				<h2>Xun Xu<mdall>, PhD, B.Eng. </mdall></h2>
			</div>
			<div class="row">
			
				<div class="col-md-2">
					<div class="thumbnail">
						<img src="./img/XuXun_Corp2.jpg" class="img-rounded">
					</div>
				</div>
				
				
				<div class="col-md-3">
					<p>
						<strong>Scientist</strong>
					</p>
					<address>
						<a href="https://www.a-star.edu.sg/i2r" target="_blank">Institute for Infocomm Research (I2R)</a><br/>
						<a href="https://www.a-star.edu.sg/" target="_blank">A*STAR</a><br/>
						Level 13 Connexis (South Tower) </br>
						Singapore 138632 <br>
						E-mail: xu_xun AT a-star.edu.sg
						<a href='https://scholar.google.com.sg/citations?user=pi0SGQUAAAAJ&hl=en' target="_blank"><span class='label label-primary'>Google Scholar</span></a>
						<a href='https://github.com/alex-xun-xu' target="_blank"><span class='label label-default'>GitHub</span></a>
						<a href='https://www.linkedin.com/in/xu-xun/' target="_blank"><span class='label label-info'>LinkedIn</span></a>
					</address>
				</div>
				
				<div class="col-md-7">
					<p>
I am a senior scientist with the Institute for Infocomm Research (I<sup>2</sup>R), A*STAR, leading the research group AI for Semiconductor. Prior to that, I worked a research fellow with the National University of Singapore from 2016.09 - 2019.11. I obtained my PhD from the Queen Mary University of London in 2016.

						
						
					</p>
					<p>	My research interests include <b>Data-Efficient Learning</b>, <b>Robust AI</b>, <b>GenAI</b> and <b>Multi-modal LLMs</b> with applications to <b>3D Data</b> and <b>Industrial Visual Inspection</b>. 
					</p>
				</div>
			</div>
	</section>
</div>


<div class='container'>

	<section id='NEWS'>
			<div class="page-header">
				<h3>NEWS<mdall></mdall></h3>
			</div>
			<div class="row">
				<div class="col-md-12">
				<!--<b>[<span style="color: red;">Call for Paper</span>]</b> We are organizing a Special Session at <a href="https://2025.ieeeicme.org/" target="_blank"><b>ICME 2025</b></a>: <b>Towards Realistic 3D Deep Learning with Limited Supervision</b>. Please find more <a href="./Ad/ICME25_SS_CFP.pdf" target="_blank">details</a>. -->
					<h4><b>Openings</b></h4>
					<b>TOP</b>: We are always looking for highly self-motivated students. Please feel free to contact me if you wish to consider the following opportunities<br>
- <b>Short-term internship</b> with paid allowance & eligible to non-Singaporean undergrad and master students.<br>
- <b>Visiting PhD/Master/Ungrad</b> funded by <a href='https://www.csc.edu.cn/' target="_blank"><b>CSC</b></a>, <a href='https://www.a-star.edu.sg/scholarships/home/international-awards/astar-research-attachment-programme-arap' target="_blank"><b>ARAP</b></a> scholarships are available. <br>
- <b>Pursuing PhD</b> with Singapore universities and A*STAR funded by <a href='https://www.a-star.edu.sg/scholarships/home/scholarships/national-science-scholarship-(phd)' target="_blank"><b>National Science Scholarship</b></a> or <a href='https://www.a-star.edu.sg/scholarships/home/scholarships/ags--scholarship' target="_blank"><b>A*STAR Graduate Scholarship</b></a> scholarship.<br> 
<!--<font style="background-color:Tomato;color:White;">Find more details for eligible <a href="./Ad/Scholarships_2023.html">scholarships</a></font><br>-->
<!--- Find more details for eligible <a href="./Ad/Scholarships_2023.html" target="_blank"><b>scholarships</b></a><br>-->
- Find details for the above scholarships in a single <a href="./Ad/ASTAR_Scholarship_26.01.pdf" target="_blank"><b>PDF</b></a>

<!-- 12nd May 2023: <font style="background-color:Tomato;color:White;">OPENING (DDL: open until filled)</font>: One full-time <b>research scientist</b> position on developing robust 3D deep learning algorithms is available with <a href='https://www.linkedin.com/jobs/view/3599956806/' target="_blank">details</a>. Please contact me for informal inquiries.<br> -->

					<h4><b>Research</b></h4>
					<h5><b>Projects</b></h5>
					- Apr 2025: <b>National Multi-Modal LLM Programme (NMLP) "Heterogeneous Preference Learning for Value-Aligned Large Language Models in Multicultural Societies: A Resource-Efficient Approach" (SGD$ 750k allocated) kickstarted in Apr 2025</b><br>
<ul>
<li> We shall develop resource efficient approaches to align the value of LLMs with human preferences from different social groups.<br>
</ul>
					- May 2023: <b>A*STAR MTC Programmatic Fund "Towards Realistic Deep Learning for 3D Vision" (SGD$ 1.1M allocated) will kickstart in Aug 2023</b><br>
<ul>
<li> We shall develop 3D deep learning techniques robust to imperfect visibility, adversarial attacks and incremental data to enable deployment in real-world applications.<br>
</ul>	
- May 2021: <b>A*STAR CDA Project "Exploiting Unlabeled Data, Cheaper Labels and Efficient Annotation for 3D 
Point Cloud Deep Learning" (EUDEA) ($SGD 238k allocated)</b>
					<ul>
					<li> My project on exploring label-efficient learning on 3D point cloud data started from Apr. 2021.<br>
					<li> We will be looking into improving the efficiency of 3D point cloud learning from several perspectives.<br>
					</ul>

					<h5><b>Publications & Services</b></h5>
					
					<div id="listContainer" class="collapsible-list" style="max-height: 350px;">
- Jan 2026: Two papers, <a href="#SuEtAl_ICLR26"><b>Patch Token as Output</b></a> and  <a href="#ChenEtAl_ICLR26"><b>PointGraph MLLM</b></a> to appear in <b>ICLR 2026</b>. Congratulations to Yongyi Su and Tiankai Chen!<br>
- Jan 2026: I was invited for a keynote talk at Artificial Intelligence with Biased or Scarce Data (<a href="https://aibsdworkshop.github.io/2026/" target="_blank"><b>AIBSD</b></a>) workshop in conjunction with AAAI 2026.<br>
- Jan 2026: One paper, <a href="#QiaoEtAl_ICASSP26"><b>SAM for 3D Segmentation</b></a> to appear in <b>ICASSP 2026</b>. Congratulations to Yuena Qiao!<br>
- Dec 2025: I am serving as the leader for AI for Semiconductor research group with Machine Intellection department, I2R.<br>
- Nov 2025: Two papers, <a href="#LiaoEtAl_AAAI26"><b>MLLM for Anomaly Detection</b></a> and <a href="#HuangEtAl_AAAI26"><b>Adapting Depth Foundation Model</b></a> to appear in <b>AAAI 2026</b>. Congratulations to Jingyi Liao and Yan Huang! See you in Singpaore.<br>
- Sep 2025: I will serve as an Area Chair for <b><a href='https://cvpr.thecvf.com/Conferences/2026' target="_blank">CVPR 2026</a></b>.<br>		
- Jul 2025: We are actively looking for paid intern students for LLM and Generative AI projects. Please contact me if you are interested and find <a href="https://www.linkedin.com/posts/xu-xun_internship-opportunities-in-llm-and-generative-activity-7348960593640398848-KLT_?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAtwPlsBY5zMm20PgjDuF0jnVcxnEli5-Sw" target="_blank">details</a>.<br>
- Jun 2025: Three papers on <a href="#ChenEtAl_ICCV25"><b>Graph Propagation for 3D OOD detection</b></a>, <a href="#LiEtAl_ICCV25_1"><b>Motion Forecasting</b></a> and <a href="#LiEtAl_ICCV25_2"><b>Scene Completing</b></a>, to appear in <b>ICCV 2025</b>. Congratulations to Tiankai Chen and Shijie Li!<br>
- Jun 2025: SG Academies South-East Asia Fellowship Programme is available to support post-doc research at A*STAR for 2 years. PhDs from ASEAN countries are eligible. More <a href="https://snas.org.sg/saseaf">details</a>.<br>
- Jun 2025: One paper on <a href="#GoodgeEtAl_ECML25"><b>3D VLM for OOD Detection</b></a> to appear in <b>ECML-PKDD</b> 2025 <br>	 
- Apr 2025: I will serve as an Area Chair for <b><a href="https://neurips.cc/" target="_blank">NeurIPS</a></b> 2025!<br>	
- Mar 2025: I will serve as an Associate Editor for Machine Vision and Applications (<b><a href="https://link.springer.com/journal/138" target="_blank">MVA</a></b>) from Mar 2025!<br>					
- Feb 2025: I will serve as an Area Chair for ACM Multimedia (<b><a href="https://acmmm2025.org/" target="_blank">ACM MM</a></b>) 2025!<br>					
- Jan 2025: Three papers on <a href="#SuEtAl_ICLR25"><b>Test-Time Data Poisoning</b></a>, <a href="#LiEtAl_ICLR25"><b>VLM Adaptation</b></a> & <a href="#CaiEtAl_ICLR25"><b>Robust matching</b></a> to appear in <b>ICLR</b> 2025. Congratulations to Yongyi Su & Yushu Li! <br>	 
- Jan 2025: Our work on <a href="#LiuEtAl_TGRS25"><b>PointSAM</b></a> was accepted by IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>). Congratulations to Nanqing Liu! <br>	
- Jan 2025: Our work on <a href="#LiEtAl_TMLR25"><b>TTA with Active Learning and Model Selection</b></a> was accepted by Transactions on Machine Learning Research (<b>TMLR</b>). Congratulations to Yushu Li! <br>	
- Dec 2024: <b>[<span style="color: red;">Call for Paper</span>]</b> We are organizing a Special Session at <a href="https://2025.ieeeicme.org/" target="_blank"><b>ICME 2025</b></a>: <b>Towards Realistic 3D Deep Learning with Limited Supervision</b>. Please find more <a href="./Ad/ICME25_SS_CFP.pdf" target="_blank">details</a>.<br>
- Nov 2024: I was awarded the <a href="https://2024.acmmm.org/outstanding-ac-reviewer" target="_blank"><strong>Outstanding Area Chair</strong></a> for ACM MM 2024. Congratulations!<br>
- Aug 2024: Our work on <a href="#LinEtAl_TITS24"><b>Active Learning for 3D Object Detection</b></a> was accepted by IEEE Transactions on Intelligent Transportation Systems (<b>T-ITS</b>). Congratulations to Jinpeng Lin! <br>	
- May 2024: I will serve as the Area Chair for British Machine Vision Conference (<b><a href="https://bmvc2024.org/" target="_blank">BMVC</a></b>) 2024!<br>
- Apr 2024: Our on <b>improving generalization of object detection on remote sensing images</b> and <b>open-set semi-supervised object detection on remote sensing images</b> are accepted by IEEE IGARSS (Oral presentation) and International Journal of Applied Earth Observation and Geoinformation. Congratulations to <a href="https://scholar.google.com/citations?user=x3dCJrAAAAAJ&hl=zh-CN" target="_blank">Nanqing Liu</a> !<br>
- Feb 2024: We are happy to share our most recent work on <b>improving the generalization of Segment Anything model</b> - <a href="https://github.com/zhang-haojie/wesam" target="_blank"><b>WeSAM</b></a>, accepted by CVF/IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>). Congratulations to <a href="https://scholar.google.com/citations?user=waixiQgAAAAJ&hl=en" target="_blank">Haojie Zhang</a> !<br>
- Feb 2024: Our work on <a href="#SuEtAl_TPAMI24">Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering Regularized Self-Training</b></a> was accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>). Congratulations to <a href="https://yysu.site/" target="_blank">Yongyi Su</a>! <br>	
- Jan 2024: Our work on <a href="#LiaoEtAl_TIP24">COFT-AD: COntrastive Fine-Tuning for Few-Shot Anomaly Detection</b></a> was accepted by IEEE Transactions on Image Processing (<b>TIP</b>). Congratulations to <a href="https://www.linkedin.com/in/jingyi-liao-bb2217164/?originalSubdomain=sg" target="_blank">Jingyi Liao</a>! <br>	
- Jan 2024: I will be serving as the Area Chair for ACM Multimedia (<b><a href="https://2024.acmmm.org/" target="_blank">ACM MM</a></b>) 2024!<br>

- Dec 2023: Our work on <a href="#SuEtAl_AAAI24">Towards Real-World Test-Time Adaptation: Tri-Net Self-Training with Balanced Normalization</b></a> was accepted by The Annual AAAI Conference on Artificial Intelligence (<b>AAAI</b>). Congratulations to <a href="https://yysu.site/" target="_blank">Yongyi Su</a>! <br>	
- Nov 2023: Our work on <a href="#LiuEtAl_TGRS23">Transformation-Invariant Network for Few-Shot Object Detection in Remote Sensing Images</b></a> was accepted by IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>). Congratulations to <a href="https://scholar.google.com/citations?user=x3dCJrAAAAAJ&hl=en" target="_blank">Nanqing Liu</a>! <br>	
- Oct 2023: Our work on <a href="#XuEtAl_NeuroComputing23">Revisiting Pretraining for Semi-Supervised Learning in the Low-Label Regime</b></a> was accepted by <b>Neurocomputing</b>. Congratulations! <br>				
- Jul 2023: Our work on <a href="#LiEtAl_ICCV23">On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion</b></a> was accepted by <b>ICCV 2023 as Oral presentation (1.8% acceptance rate)</b>. Congratulations to <a href="https://yushu-li.github.io/">Yushu Li</a>!<br>
- May 2023: Our work on <a href="#SuEtAl_TCSVT23">Weakly Supervised 3D Point Cloud Segmentation via Multi-Prototype Learning</b></a> was accepted by IEEE Transactions on Circuits and System for Video Technology (<b>TCSVT</b>). Congratulations to <a href="https://yysu.site/">Yongyi Su</a>!<br>
- Jan 2023: Our work on <a href="#NguyenEtAl_ML23">Diverse and consistent multi-view networks for semi-supervised regression</b></a> was accepted by <b>ECML PKDD Journal Track 2023</b>.<br>
- Sep 2022: Our work on <a href="#SuEtAl_NeurIPS22">Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering</b></a> was accepted by <b>NeurIPS 2022</b>. Congratulations to <a href="https://yysu.site/" target="_blank">Su Yongyi</a>!<br>
- Jun 2022: Our work on <b>Open-Set Semi-Supervised Learning for 3D Point Cloud Understanding</b> was accepted by <b>ICPR 2022</b> as Oral presentation.<br>
- May 2022: Our work on <a href="#XuEtAl_TIP22">SemiCurv: Semi-Supervised Curvilinear Structure Segmentation</b></a> was accepted by IEEE Transactions on Image Processing (<b>TIP</b>).<br>
- May 2022: Our work on <a href="#JiangEtAl_TIP22">MA-GANet: A Multi-Attention Generative Adversarial Network for Defocus Blur Detection</b></a> was accepted by IEEE Transactions on Image Processing (<b>TIP</b>).<br>
- Nov 2021: Our work on <b>Automatic Data Augmentation for 3D Point Cloud</b> has appeared in BMVC 2021</b>. Code is available <a href="https://github.com/RosettaWYzhang/AdaPC" target="_blank">here</a>.<br>
- Jun 2021: The first 3D affordance prediction dataset <a href="#DengEtAl_CVPR21">3D AffordanceNet: A Benchmark for Visual Object Affordance Understanding</b></a> has appeared in <b>CVPR 2021</b>. Code is available <a href="https://andlollipopde.github.io/3D-AffordanceNet" target="_blank">here</a>.<br>
- Mar 2021: Our work on <a href="#XuEtAl_TCSVT21">Learning Clustering for Motion Segmentation</b></a> has appeared in IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>).

  </div>
  <button id="toggleButton" class="toggle-button">Past News</button>

  <script>
    const listContainer = document.getElementById('listContainer');
    const toggleButton = document.getElementById('toggleButton');

    let isCollapsed = true; // Start in collapsed state

    toggleButton.addEventListener('click', () => {
      if (isCollapsed) {
        listContainer.style.maxHeight = 'none'; // Expand to show all items
        toggleButton.textContent = 'Collapse';
      } else {
        listContainer.style.maxHeight = '350px'; // Collapse to fixed height
        toggleButton.textContent = 'Past News';
      }
      isCollapsed = !isCollapsed; // Toggle state
    });
  </script>
					
					
					
					
		

					<!-- 
					<h4></h4>
					Jul 2021: <b>PostDoc Fellowship Opportunities</b><br>
					<li> You will have a chance to carry out postdoc research in A*STAR with competitive fellowship if you are ASEAN citizenship. More details can be found at <a href="https://snas.org.sg/aseanfellowship" target="_blank">check your availibity</a>. Please contact if you are qualified and interested. Deadline is 30 Nov 2021. 
					-->
					<h4></h4>
					
				</div>
			
				<!-- <div class="col-md-12">
					<h4></h4>
					Nov 2020: <b>PhD/Postgraduate/Undergraduate Scholarship Opportunities</b><br>
					<ul>
					<li> We are looking for highly motivated international students who wish to do PhD in A*STAR, NUS, NTU, SUTD. We provide <b>full scholarship under the SINGA program</b> (<a href='https://www.a-star.edu.sg/Scholarships/for-graduate-studies/singapore-international-graduate-award-singa' target="_blank">check your eligibility</a>).<br>
					<li> We also welcome international full-time PhD students who wish to do research attachment (1-2 years research with A*STAR). <b>Full scholarship under the ARAP program</b> will be provided during the attachment period in Singapore (<a href='https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme-(arap)' target="_blank">Check your eligibility</a>)<br>
					<li> We provide scholarship for talented postgraduate/undergraduate students who wish to do research attachment (2-6 months with A*STAR) or prepare to apply for PhD under the SIPGA program (<a href='https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies/singapore-international-pre-graduate-award-(sipga)' target="_blank">Check your availability</a>).
					</ul>
				</div> -->
			</div>
		</section>
	
	</section>

</div>


<div class='container'>

	<section id='ABOUTME'>
			<div class="page-header">
				<h3>About Me<mdall></mdall></h3>
			</div>
			<div class="row">
				<div class="col-md-5">
					<h4>Education Background</h4>
					<ul>
						<li>PhD in Computer Science, Queen Mary University of London, 2016<br>
							Thesis: <a href="https://www.dropbox.com/s/zc4m6yvjh49t6wu/Xu_Thesis_Final.pdf?dl=0" target="_blank">Semantic Spaces for Video Analysis of Behaviour</a> <br>
							Supervisors: Prof. Shaogang Gong, Prof. Timothy Hospedales and Dr. Tao Xiang
						<li>M.Sc in Control Theory and Engineering, Sichuan University, 2012<br>
							Supervisor: Prof. Yusheng Liu
						<li>B.Eng in Automation, Sichuan University, 2010<br>
						
					</ul>
				</div>
				<div class="col-md-7">
					<h4>Professional Experience</h4>
					<ul>
						<li>Scientist / Senior Scientist with I<sup>2</sup>R, A*STAR, Singapore<br>
							2019.12-Now<br>
						<li>Research Fellow in School of Computing, National University of Singapore<br>
							2019.4-2019.12<br>
							Supervisors: Prof. Gim Hee Lee
						<li>Research Fellow in Electrical and Computer Engineering, National University of Singapore<br>
							2016.9-2019.3<br>
							Supervisors: Prof. Loong-Fah Cheong
					</ul>
				</div>
			</div>
			
			<div class="row">
				<div class="col-md-5">
					<h4>Academic Services</h4>
						<h5><b>Member</b></h5>
						<ul>
							<li>IEEE Senior Member</li>
						</ul>
						
						<h5><b>Journal Reviewer</b></h5>
						<ul>
							<li> TPAMI, IJCV, TIP, TNNLS, TMLR, TCSVT, etc. </li>
							<!--  <li> Transactions on Machine Learning Research (TMLR) </li>
							<li> IEEE Transactions on Image Processing (TIP)</li>
							<li> IEEE Transactions on Neural Networks and Learning Systems (TNNLS) </li>
							<li> ACM Transactions on Knowledge Discovery from Data (TKDD)</li>
							<li> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li> -->

							
						</ul>
						<h5><b>Conference Reviewer</b></h5>
						<ul>
							<li> NeurIPS, ICLR, ICML, CVPR, ECCV, ICCV, etc. </li>
							<!--  <li>  </li>
							<li> ICML </li>
							<li> CVPR</li>
							<li> ECCV </li>
							<li> ICCV </li> -->
						</ul>
						
						<!-- <h5><b>Journal Reviewer</b></h5>
						<ul>
							<li> TPAMI, IJCV, TIP, TNNLS, TMLR, TCSVT, etc. </li>
							<!--  <li> Transactions on Machine Learning Research (TMLR) </li>
							<li> IEEE Transactions on Image Processing (TIP)</li>
							<li> IEEE Transactions on Neural Networks and Learning Systems (TNNLS) </li>
							<li> ACM Transactions on Knowledge Discovery from Data (TKDD)</li>
							<li> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li> 

							
						</ul>
						<h5><b>Conference Reviewer</b></h5>
						<ul>
							<li> NeurIPS, ICLR, ICML, CVPR, ECCV, ICCV, etc. </li>
							<!--  <li>  </li>
							<li> ICML </li>
							<li> CVPR</li>
							<li> ECCV </li>
							<li> ICCV </li> 
						</ul> -->
						
				</div>

				<div class="col-md-7">
						<br>
						<br>
						<h5><b>Associate Editor</b></h5>
						<ul>
							<li> Machine Vision and Applications 2025.03 - Now
						</ul>
						<h5><b>Area Chair</b></h5>
						<ul>
							<li> IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2026
							<li> Annual Conference on Neural Information Processing Systems (NeurIPS) 2025
							<li> ACM Multimedia (ACM MM) 2024, 2025
							<li> British Machine Vision Conference (BMVC) 2024, 2025
							<li> IEEE International Conference on Multimedia & Expo (ICME) 2025
						</ul>
						
				</div>
			</div>
		</section>
	
	</section>

</div>

<div class='container'>

	<section id='PEOPLE'>
		<div class="page-header">
			<h3>People<mdall></mdall></h3>
		</div>
		
		<div>
			<!--<h4>Staffs</h4>
			 <ul>
			<li><a href="https://scholar.google.co.uk/citations?user=XKupj84AAAAJ&hl=en" target="_blank">Dr. Adam Goodge</a> (Research Scientist, Co-RO)</a></li>
			<li><a href="https://www.linkedin.com/in/jingyi-liao-bb2217164/?originalSubdomain=sg" target="_blank">Jingyi Liao</a> (Research Engineer, Co-RO)</a></li>
			</ul> -->
			<h4>Students</h4>
			<ul>
			<li><a href="https://scholar.google.com/citations?user=WPdQj24AAAAJ&hl=en">Fady Rezk</a> (ARAP funded visiting PhD Student from the University of Edinburgh, Co-supervised with Prof. Timothy Hospedales & Dr. Chuan-Sheng Foo, 2025.02-Now.)</li>
			<li><a href=#>Zheng Liang</a> (CSC funded visiting PhD Student from University of Chinese Academy of Sciences, Co-supervise with Dr. Yang Feng, 2025.09-Now)</li>
			<li><a href="https://openreview.net/profile?id=%7ETiankai_Chen3" target="_blank">Mr. Tiankai Chen</a> (CSC funded visiting PhD Student from Southwest Jiaotong University, 2025.10-Now)</li>
			<li><a href=#>Jinya Sakurai</a> (Visiting Master Student from the University of Tokyo, 2025.11-Now)</li>
			<li><a href=#>Zirui Cheng</a> (Visiting Master Student from National University of Singapore, 2025.09-Now)</li>
			<li><a href=#>Bowen Zheng</a> (Visiting Master Student from National University of Singapore, 2025.09-Now)</li>


			</ul>
			<h4>Past Members</h4>
			<ul>
			<li><a href="linkedin.com/in/harshithaveeravalli" target="_blank">Ms. Harshi Veeravalli</a> (Visiting Undergraduate Student from Carnegie Mellon University, 2025.07-2025.12)</li>
			<li><a href="https://yysu.site/" target="_blank">Yongyi Su</a> (CSC funded visiting PhD Student from South China University of Technology, 2023.11-2025.11)</li>
			<li><a href=#>Jinnapat Yana</a> (SINGA scholarship funded PhD student, 2024.08-2025.08)</li>
			<li><a href=#>Yifan Liu</a> (Project Funded Visiting Master Student from National University of Singapore, Co-supervised with Dr. Xulei Yang, 2024.08-2025.05.)</li>
			<li>Mr. Zelin Yue (CSC funded visiting PhD Student from University of Chinese Academy of Sciences, Co-supervised with Prof. Bharadwaj VEERAVALLI, 2024.02-2025.1.)</li>
			<li><a href="https://github.com/azztt" target="_blank">Mr. Anweshan Bor</a> (Project Funded Master Student from National University of Singapore, Co-supervised with Jingyi Liao, 2024.06-2025.1.)</li>
			<li><a href="https://scholar.google.com/citations?user=x3dCJrAAAAAJ&hl=en" target="_blank">Nanqing Liu</a> (CSC funded visiting PhD Student from Southwest Jiaotong University, Co-supervised with Dr. Lile Cai & Dr. Chuan Sheng Foo, 2023.02-2024.12)</li>
			<li><a href="https://yushu-li.github.io/" target="_blank">Yushu Li</a> (SIPGA funded Master Student from South China University of Technology, 2024.03-2024.09)</li>
			<li><a href="https://cxliu0.github.io/" target="_blank">Chengxin Liu</a> (University funded visiting PhD Student from Huazhong University of Science and Technology, 2023.11-2024.08)</li>
			<li>Rong Pang (Visiting PhD Student from Southwest Jiaotong University, 2023.03-2023.12)</li>
			<li><a href="https://rosettawyzhang.github.io/" target="_blank">Wanyue Zhang</a> (Research Engineer Co-RO, 2020.09-2021.09, Now pursing PhD at Max Planck Institute for Informatics)</li>
			</ul>

		</div>
</div>


<div class='container'>

	<section id='PUBLICATION'>
	
		<div class="page-header">
			<h3>Selected Publications<mdall></mdall></h3>
		</div>
			
		Visit my <a href='https://scholar.google.com.sg/citations?user=pi0SGQUAAAAJ&hl=en' target="_blank"><span class='label label-primary'>Google Scholar</span></a>
 for a complete list of publications.<br>
<b>*</b> Corresponding Author   <b>#</b> Equal Contribution

		<h4>Preprint</h4>

		
		
		
		
		<div class="row" id="LiaoEtAl_RODA">
			<div class="col-md-3"><img src="./img/LiaoEtAl_ICCV25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Robust Distribution Alignment for Industrial Anomaly Detection under Distribution Shift</strong></span>
				<a href="https://arxiv.org/abs/2503.14910" target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Jingyi Liao, <b>Xun Xu*</b>, Yongyi Su, Rong-Cheng Tu, Yifan Liu, Dacheng Tao & Xulei Yang<br>
					ArXiv, 2025</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="LiuEtAl_MVEAD">
			<div class="col-md-3"><img src="./img/LiuEtAl_MVEAD.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Multi-View Industrial Anomaly Detection with Epipolar Constrained Cross-View Fusion</strong></span>
				<a href="https://www.arxiv.org/abs/2503.11088" target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Yifan Liu, <b>Xun Xu*</b>, Shijie Li, Jingyi Liao & Xulei Yang<br>
					ArXiv, 2025</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="LinEtAl_TTAAdv3D">
			<div class="col-md-3"><img src="./img/LinEtAl_TTAAdv3D.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Improving Adversarial Robustness for 3D Point Cloud Recognition at Test-Time through Purified Self-Training</strong></span>
				<a href="https://arxiv.org/pdf/2409.14940" target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Jinpeng Lin, Xulei Yang, Tianrui Li & <b>Xun Xu*</b><br>
					ArXiv, 2024</span>
			</div>
		</div>
		<br>
		
		<div class="row">
			<div class="col-md-3"><img src="./img/ChenEtAl_ICCV23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>STFAR: Improving Object Detection Robustness at Test-Time by Self-Training with Feature Alignment Regularization</strong></span>
				<a href="https://arxiv.org/abs/2303.17937"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Yijin Chen, <b>Xun Xu*</b>, Yongyi Su, Kui Jia<br>
					ArXiv, 2023 </span>
			</div>
		</div>
		<br>
		
		<h4>2026</h4>

		<div class="row" id="SuEtAl_ICLR26">
			<div class="col-md-3"><img src="./img/SuEtAl_ICLR26.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs</strong></span>
				<a href="https://arxiv.org/abs/2510.01954" target="_blank"><span class="label label-default">PDF</span></a> <a href="https://github.com/Gorilla-Lab-SCUT/PaDT"  target="_blank"><span class="label label-success" >ProjectPage</span></a>

				<br>
				<span class="details">Yongyi Su, Haojie Zhang, Shijie Li*, Nanqing Liu, Jingyi Liao, Junyi Pan, Yuan Liu, Xiaofen Xing, Chong Sun, Chen Li, Nancy F. Chen, Shuicheng Yan, Xulei Yang, <b>Xun Xu*</b><br>
					International Conference on Learning Representations (<b>ICLR</b>), 2026</span>
			</div>
		</div>
		<br>

		<div class="row" id="ChenEtAl_ICLR26">
			<div class="col-md-3"><img src="./img/ChenEtAl_ICLR26.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Test-Time Optimization of 3D Point Cloud LLM via Manifold-Aware In-Context Guidance and Refinement</strong></span>
				<a href="https://openreview.net/forum?id=qsra0EsUpe" target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Tiankai Chen, Nanqing Liu, Li Yang, Xulei Yang, Tianrui Li, <b>Xun Xu*</b><br>
					International Conference on Learning Representations (<b>ICLR</b>), 2026</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="HuangEtAl_AAAI26">
			<div class="col-md-3"><img src="./img/HuangEtAl_AAAI26.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Enhancing Generalization of Depth Estimation Foundation Model via Weakly-Supervised Adaptation with Regularization</strong></span>
				<a href="" target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Yan Huang, Yongyi Su, Xin Lin, Le Zhang & <b>Xun Xu*</b><br>
					The Annual AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2026</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="LiaoEtAl_AAAI26">
			<div class="col-md-3"><img src="./img/LiaoEtAl_AAAI26.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>AD-FM: Multimodal LLMs for Anomaly Detection via Multi-Stage Reasoning and Fine-Grained Reward Optimization</strong></span>
				<a href="https://arxiv.org/abs/2508.04175" target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Jingyi Liao, Yongyi Su, Rong-Cheng Tu*, Zhao Jin, Wenhao Sun, Yiting Li, Dacheng Tao, <b>Xun Xu*</b> & Xulei Yang<br>
					The Annual AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2026</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="QiaoEtAl_ICASSP26">
			<div class="col-md-3"><img src="./img/QiaoEtAl_ICASSP26.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>SAM-Guided Multi-view Fusion for Weakly Supervised 3D Point Cloud Segmentation</strong></span>
				<a href="./Doc/Publication/2026/QiaoEtAl_ICASSP26.pdf" target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Yuena Qiao, Nanqing Liu*, Yongyi Su, Shijie Li, Xulei Yang, Bihan Wen, Nancy Chen, Tianrui Li, <b>Xun Xu</b><br>
					IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2026</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="GaoEtAl_TMM26">
			<div class="col-md-3"><img src="./img/GaoEtAl_TMM26.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Investigate Interactive Semantic Segmentation via an Uncertainty Mining View</strong></span>
				<a href="https://ieeexplore.ieee.org/document/11275891" target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Yutong Gao, Congyan Lang, Fayao Liu, <b>Xun Xu</b>, Yuanzhouhan Cao, Lijuan Sun, Yunchao Wei<br>
					IEEE Transactions on Multimedia (<b>TMM</b>), 2026</span>
			</div>
		</div>
		<br>
		
		<h4>2025</h4>
		
		

		<div class="row" id="ChenEtAl_ICCV25">
			<div class="col-md-3"><img src="./img/ChenEtAl_ICCV25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation</strong></span>
				<a href="https://arxiv.org/pdf/2506.22375"  target="_blank"><span class="label label-default">PDF</span></a> <a href="https://github.com/handsome999KK/GSP_OOD"  target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<br>
				<span class="details">Tiankai Chen, Yushu Li, Adam Goodge, Fei Teng, Xulei Yang, Tianrui Li & <b>Xun Xu*</b><br>
					IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2025</span> 
			</div> 
		</div>
		<br>

		<div class="row" id="LiEtAl_ICCV25_1">
			<div class="col-md-3"><img src="./img/LiEtAl_ICCV25_1.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Future-Aware Interaction Network For Motion Forecasting</strong></span>
				<a href="https://arxiv.org/pdf/2503.06565?"  target="_blank"><span class="label label-default">PDF</span></a>
				<br>
				<span class="details">Shijie Li, <b>Xun Xu</b>, Si Yong Yeo, Xulei Yang<br>
					IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2025</span> 
			</div> 
		</div>
		<br>

		<div class="row" id="LiEtAl_ICCV25_2">
			<div class="col-md-3"><img src="./img/LiEtAl_ICCV25_2.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Global-Aware Monocular Semantic Scene Completion with State Space Models</strong></span>
				<a href="https://arxiv.org/pdf/2503.06569?"  target="_blank"><span class="label label-default">PDF</span></a>
				<br>
				<span class="details">Shijie Li, Zhongyao Cheng, Rong Li, Shuai Li, Juergen Gall, <b>Xun Xu</b>, Xulei Yang<br>
					IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2025</span> 
			</div> 
		</div>
		<br>

		
		<div class="row" id="SuEtAl_ICLR25">
			<div class="col-md-3"><img src="./img/SuEtAl_ICLR25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>On the Adversarial Risk of Test Time Adaptation: An Investigation into Realistic Test-Time Data Poisoning</strong></span>
				<a href="https://openreview.net/forum?id=7893vsQenk"  target="_blank"><span class="label label-default">PDF</span></a> <a href="https://github.com/Gorilla-Lab-SCUT/RTTDP"  target="_blank"><span class="label label-success" >ProjectPage</span></a>

				<br>
				<span class="details">Yongyi Su, Yushu Li, Nanqing Liu, Kui Jia, Xulei Yang, Chuan-Sheng Foo & <b>Xun Xu*</b><br>
					International Conference on Learning Representations (<strong>ICLR</strong>), 2025</span> 
			</div> 
		</div>
		<br>
		
		
		<div class="row" id="LiEtAl_ICLR25">
			<div class="col-md-3"><img src="./img/LiEtAl_ICLR25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Efficient and Context-Aware Label Propagation for Zero-/Few-Shot Training-Free Adaptation of Vision-Language Model</strong></span>
				<a href="https://openreview.net/forum?id=D10yarGQNk"  target="_blank"><span class="label label-default">PDF</span></a> <a href="https://github.com/Yushu-Li/ECALP"  target="_blank"><span class="label label-success" >ProjectPage</span></a>

				<br>
				<span class="details">Yushu Li, Yongyi Su, Adam Goodge, Kui Jia & <b>Xun Xu*</b><br>
					International Conference on Learning Representations (<strong>ICLR</strong>), 2025</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="LiEtAl_TMLR25">
			<div class="col-md-3"><img src="./img/LiEtAl_TMLR25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Exploring Human-in-the-Loop Test-Time Adaptation by Synergizing Active Learning and Model Selection</strong></span>
				<a href="https://openreview.net/forum?id=P09rAv8UH7"  target="_blank"><span class="label label-default">PDF</span></a> <a href="https://github.com/Yushu-Li/HILTTA"  target="_blank"><span class="label label-success" >ProjectPage</span></a>

				<br>
				<span class="details">Yushu Li, Yongyi Su, Xulei Yang, Kui Jia & <b>Xun Xu*</b><br>
					Transactions on Machine Learning Research (<b>TMLR</b>), 2025</span>
			</div>
		</div>
		<br>

		<div class="row" id="GoodgeEtAl_ECML25">
			<div class="col-md-3"><img src="./img/GoodgeEtAl_ECML25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation</strong></span>
				<a href="./Doc/Publication/2025/GoodgeEtAl_ECML25.pdf"  target="_blank"><span class="label label-default">PDF</span></a> 

				<br>
				<span class="details">Adam Goodge, <b>Xun Xu*</b>, Bryan Hooi, Wee Siong Ng, Jingyi Liao,
Yongyi Su, and Xulei Yang<br>
					European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Database (<strong>ECML-PKDD</strong>), 2025</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="LiuEtAl_TGRS25">
			<div class="col-md-3"><img src="./img/LiuEtAl_TGRS25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>PointSAM: Pointly-Supervised Segment Anything Model for Remote Sensing Images</strong></span>
				<a href="https://arxiv.org/abs/2409.13401"  target="_blank"><span class="label label-default">PDF</span></a> <a href="https://github.com/Lans1ng/PointSAM"  target="_blank"><span class="label label-success" >ProjectPage</span></a>

				<br>
				<span class="details">Nanqing Liu, <b>Xun Xu</b>*, Yongyi Su, Haojie Zhang & Heng-Chao Li*</b><br>
					IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), 2025</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="MoEtAl_ICASSP25">
			<div class="col-md-3"><img src="./img/MoEtAl_ICASSP25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Distribution Alignment Informed Thresholding for Semi-Supservised Curvilinear Structure Segmentation</strong></span>
				<a href="./Doc/Publication/2025/MoEtAl_ICASSP25.pdf"  target="_blank"><span class="label label-default">PDF</span></a> <a href="https://github.com/alex-xun-xu/SemiDial"  target="_blank"><span class="label label-success" >ProjectPage</span></a>

				<br>
				<span class="details">Yuhao Mo, Po Peng, Bihan Wen, Xulei Yang, Ce Zhu & <b>Xun Xu*</b><br>
					IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2025</span>
			</div>
		</div>
		<br>
		
		
		<div class="row" id="CaiEtAl_ICLR25">
			<div class="col-md-3"><img src="./img/CaiEtAl_ICLR25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Evidential Learning-based Certainty Estimation for Robust Dense Feature Matching</strong></span>
				<a href="https://openreview.net/forum?id=4NWtrQciRH"  target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Lile Cai, Chuan-Sheng Foo, <b>Xun Xu</b>, Zaiwang Gu, Jun Cheng & Xulei Yang<br>
					International Conference on Learning Representations (<strong>ICLR</strong>), 2025</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="ZhaoEtAl_TIP25">
			<div class="col-md-3"><img src="./img/ZhaoEtAl_TIP25.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>SDCoT++: Improved Static-Dynamic Co-Teaching for Class-Incremental 3D Object Detection</strong></span>
				<a href="./Doc/Publication/2025/ZhaoEtAl_TIP25.pdf"  target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Na Zhao, Peisheng Qian, Fang Wu, <b>Xun Xu</b>, Xulei Yang & Gim Hee Lee<br>
					IEEE Transactions on Image Processing (<b>TIP</b>), 2025</span>
			</div>
		</div>
		<br>
		
		
		<h4>2024</h4>

		<div class="row" id="SuEtAl_TPAMI24">
			<div class="col-md-3"><img src="./img/SuEtAl_TPAMI23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering Regularized Self-Training</strong></span>
				<a href="https://arxiv.org/abs/2303.10856"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/Gorilla-Lab-SCUT/TTAC2" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Yongyi Su#, <b>Xun Xu#*</b>, Tianrui Li and Kui Jia<br>
					IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2024 </span>
			</div>
		</div>
		<br>

		<div class="row" id="ZhangEtAl_CVPR24">
			<div class="col-md-3"><img src="./img/ZhangEtAl_CVPR24.png" width="260" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Improving the Generalization of Segmentation Foundation Model under Distribution Shift via Weakly Supervised Adaptation</strong></span>
				<a href="https://arxiv.org/abs/2312.03502"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/zhang-haojie/wesam" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<!-- <a href="./Doc/Publication/2023/LiEtAl_ICCV23.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Haojie Zhang, Yongyi Su, <b>Xun Xu*</b>, and Kui Jia<br>
					IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024</span>
			</div>
		</div>
		<br>



		<div class="row" id="LiaoEtAl_TIP24">
			<div class="col-md-3"><img src="./img/LiaoEtAl_TIP24.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>COFT-AD: COntrastive Fine-Tuning for Few-Shot Anomaly Detection</strong></span>
				<a href="./Doc/Publication/2024/LiaoEtAl_TIP24.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TRIBE" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2024/LiaoEtAl_TIP24.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Jingyi Liao, <b>Xun Xu*</b>, Manh Cuong Nguyen, Adam Goodge and Chuan Sheng Foo<br>
					IEEE Transactions on Image Processing (<b>TIP</b>), 2024 </span>
			</div>
		</div>
		<br>

		<div class="row" id="SuEtAl_AAAI24">
			<div class="col-md-3"><img src="./img/SuEtAl_TRIBE23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Towards Real-World Test-Time Adaptation: Tri-Net Self-Training with Balanced Normalization</strong></span>
				<a href="https://arxiv.org/pdf/2309.14949.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/Gorilla-Lab-SCUT/TRIBE" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Yongyi Su, <b>Xun Xu*</b> and Kui Jia<br>
					Annual AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2024 </span>
			</div>
		</div>
		<br>
		
		<div class="row" id="LinEtAl_TITS24">
			<div class="col-md-3"><img src="./img/LiangEtAl_TITS22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Exploring Diversity-based Active Learning for 3D Object Detection in Autonomous Driving</strong></span>
				<a href="https://arxiv.org/abs/2205.07708"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/Linkon87/Exploring-Diversity-based-Active-Learning-for-3D-Object-Detection-in-Autonomous-Driving" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Jinpeng Lin, Zhihao Liang, Shengheng Deng, Lile Cai, Tao Jiang, Tianrui Li, Kui Jia and <b>Xun Xu*</b><br>
					IEEE Transactions on Intelligent Transportation Systems (<b>T-ITS</b>), 2024 </span>
			</div>
		</div>
		<br>

		
		
		<div class="row" id="LiuEtAl_JAG24">
			<div class="col-md-3"><img src="./img/LiuEtAl_OSSOD23.png" width="250" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Semi-Supervised Object Detection with Uncurated Unlabeled Data for Remote Sensing Images</strong></span>
				<a href="https://www.sciencedirect.com/science/article/pii/S1569843224001687"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/Lans1ng/OSSOD" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<br>
				<span class="details">Nanqing Liu, <b>Xun Xu*</b>, Yingjie Gao and Heng-Chao Li<br>
					International Journal of Applied Earth Observation and Geoinformation, 2024 </span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/Shi_EtAl_ActivePC.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Label-Efficient Point Cloud Semantic Segmentation: A Holistic Active Learning Approach</strong></span>
				<a href="https://www.worldscientific.com/doi/10.1142/S281103232440006X?srsltid=AfmBOoqjH-DAdw67-Pnp0SmisjcixNv-cXVvX2hBXuQwNrIR4SQAMUAL"  target="_blank"><span class="label label-default">PDF</span></a>
				<!--<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>-->
				<!--<a href="./Doc/Publication/2020/LuEtAl_ICLR2021.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>-->
				<br>
				<span class="details">Xian Shi#, Lile Cai, Ke Chen, Chuan Sheng Foo, Kui Jia and <b>Xun Xu*</b><br>
					World Scientific Annual Review of Artificial Intelligence, 2024</span>
			</div>
		</div>
		<br>


		<div class="row" id="LiuEtAl_IGARSS24">
			<div class="col-md-3"><img src="./img/LiuEtAl_IGARSS24.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>CLIP-guided Source-free Object Detection in Aerial Images</strong></span>
				<a href="https://arxiv.org/html/2401.05168v1"  target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Nanqing Liu, <b>Xun Xu</b>, Yongyi Su, Chengxin Liu, Peiliang Gong, Heng-Chao Li<br>
					The International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>), 2024 (Oral Presentation & Travel Grant)</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="ZhangEtAl_ML24">
			<div class="col-md-3"><img src="./img/ZhangEtAl_ML24.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Deep Negative Correlation Classification</strong></span>
				<a href="https://arxiv.org/pdf/2212.07070"  target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Le Zhang, Qibin Hou, Yun Liu, Jia-Wang Bian, <b>Xun Xu</b>, Joey Tianyi Zhou and Ce Zhu<br>
					Machine Learning (<b>ML</b>), 2024</span>
			</div>
		</div>
		<br>
		
		<div class="row" id="FanEtAl_TIV24">
			<div class="col-md-3"><img src="./img/FanEtAl_TIV24.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Holistic and Contextual Evidential Stereo-LiDAR Fusion for Depth Estimation</strong></span>
				<a href="./Doc/Publication/2024/FanEtAl_TIV24.pdf"  target="_blank"><span class="label label-default">PDF</span></a>

				<br>
				<span class="details">Jiayuan Fan, Haixiang Chen, Weide Liu, <b>Xun Xu</b> and Jun Cheng<br>
					IEEE Transactions on Intelligent Vehicles(<b>TIV</b>), 2024</span>
			</div>
		</div>
		<br>
		
		
	
		
		


		<h4>2023</h4>

		<div class="row" id="LiEtAl_ICCV23">
			<div class="col-md-3"><img src="./img/LiEtAl_ICCV23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion</strong></span>
				<a href="https://arxiv.org/abs/2308.09942"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://yushu-li.github.io/owttt-site/" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2023/LiEtAl_ICCV23.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Yushu Li, <b>Xun Xu*</b>, Yongyi Su and Kui Jia<br>
					IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023 (<b>Oral Presentation</b> 1.8% acceptance rate)</span>
			</div>
		</div>
		<br>

		<div class="row" id="XuEtAl_NeuroComputing23">
			<div class="col-md-3"><img src="./img/XuEtAl_TNNLS22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Revisiting Pretraining for Semi-Supervised Learning in the Low-Label Regime</strong></span>
				<a href="https://arxiv.org/abs/2205.03001"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details"><b>Xun Xu</b>, Jingyi Liao, Lile Cai, Manh Cuong Nguyen, Kangkang Lu, Wanyue Zhang, Yasin Yazici and Chuan Sheng Foo<br>
					<b>Neurocomputing</b>, 2023 </span>
			</div>
		</div>
		<br>
		
		<div class="row" id="SuEtAl_TCSVT23">
			<div class="col-md-3"><img src="./img/SuEtAl_TCSVT23.png" width="250" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Weakly Supervised 3D Point Cloud Segmentation via Multi-Prototype Learning</strong></span>
				<a href="https://arxiv.org/abs/2205.03137"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2023/SuEtAl_TCSVT23.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Yongyi Su, <b>Xun Xu*</b> and Kui Jia<br>
					IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2023 </span>
			</div>
		</div>
		<br>

		<div class="row" id="LiuEtAl_TGRS23">
			<div class="col-md-3"><img src="./img/LiuEtAl_TGRS23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Transformation-Invariant Network for Few-Shot Object Detection in Remote Sensing Images</strong></span>
				<a href="https://arxiv.org/abs/2303.06817"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Nanqing Liu, <b>Xun Xu*</b>, Turgay Celik, Zongxin Gan and Heng-Chao Li<br>
					IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), 2023 </span>
			</div>
		</div>
		<br>



		<div class="row" id="NguyenEtAl_ML23">
			<div class="col-md-3"><img src="./img/NguyenEtAl_ML23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Diverse and consistent multi-view networks for semi-supervised regression</strong></span>
				<a href="https://openreview.net/pdf?id=J9_7t9m8xRj"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Cuong Nguyen, Arun Raja, Le Zhang, <b>Xun Xu</b>, Balagopal Unnikrishnan, Mohamed Ragab, Kangkang Lu and Chuan-Sheng Foo<br>
					Machine Learning (<b>ML</b>), 2023 </span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/LuEtAl_ICASSP23.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>On Adversarial Robustness of Audio Classifiers</strong></span>
				<a href=""  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<!--<a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Kangkang Lu, Manh Cuong Nguyen, <b>Xun Xu</b> and Chuan Sheng Foo
					  International Conference on Acoustics, Speech, & Signal Processing (<b>ICASSP 2023</b>) </span>
			</div>
		</div>
		<br>

		


		<h4>2022</h4>

		<div class="row" id="SuEtAl_NeurIPS22">
			<div class="col-md-3"><img src="./img/SuEtAl_NeurIPS22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering</strong></span>
				<a href="https://arxiv.org/abs/2206.02721"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/Gorilla-Lab-SCUT/TTAC" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<!-- <a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a> -->
				<br>
				<span class="details">Yongyi Su#, <b>Xun Xu#*</b> and Kui Jia<br>
					Advances in Neural Information Processing Systems (<b>NeurIPS 2022</b>) </span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/XuEtAl_TIP22.png" width="250" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>SemiCurv: Semi-Supervised Curvilinear Structure Segmentation</strong></span>
				<a href="https://arxiv.org/abs/2205.08706"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/alex-xun-xu/SemiCurv" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2022/XuEtAl_TIP22.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details"><b>Xun Xu</b>, Manh Cuong Nguyen, Yasin Yazici, Kangkang Lu, Hlaing Min, Chuan Sheng Foo<br>
					IEEE Transactions on Image Processing (<b>TIP</b>), 2022 </span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/JiangEtAl_TIP22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>MA-GANet: A Multi-Attention Generative Adversarial Network for Defocus Blur Detection</strong></span>
				<a href="./Doc/Publication/2022/JiangEtAl_TIP22.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Zeyu Jiang, <b>Xun Xu*</b>, Le Zhang, Chao Zhang, Chuan Sheng Foo and Ce Zhu<br>
					IEEE Transactions on Image Processing (<b>TIP</b>), 2022 </span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/ShiEtAl_ICPR22.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Open-Set Semi-Supervised Learning for 3D Point Cloud Understanding</strong></span>
				<a href="https://arxiv.org/abs/2205.01006"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://github.com/SCUT-ShiXian/Open-Set-Semi-Supervised-Learning-for-3D-Point-Cloud-Understanding" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2022/ShiEtAl_ICPR22.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Xian Shi, <b>Xun Xu*</b>, Wanyue Zhang, Xiatian Zhu, Chuan Sheng Foo and Kui Jia<br>
					International Conference on Pattern Recognition (<b>ICPR 2022</b>) (Oral Presentation)</span>


			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/JoshiEtAl_TNNLS21.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>On Representation Knowledge Distillation for Graph Neural Networks</strong></span>
				<a href="https://arxiv.org/abs/2111.04964"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2022/ChaitanyaEtAl_TNNLS22.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Chaitanya K. Joshi, Fayao Liu, <b>Xun Xu</b>, Jie Lin and Chuan Sheng Foo<br>
					IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>), 2022 </span>
			</div>
		</div>
		<br>

		


		
		

		
		<h4>2021</h4>


		<div class="row" id="XuEtAl_TCSVT21">
			<div class="col-md-3"><img src="./img/XuEtAl_TCSVT2021.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Learning Clustering for Motion Segmentation</strong></span>
				<a href="./Doc/Publication/2021/XuEtAl_TCSVT21.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="https://github.com/alex-xun-xu/LearnSubspaceMoSeg" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2021/XuEtAl_TCSVT21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details"><b>Xun Xu</b>, Loong-Fah Cheong, Zhuwen Li, Le Zhang and Ce Zhu<br>
					IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2021</span>
			</div>
		</div>
		<br>


		<div class="row" id="DengEtAl_CVPR2021">
			<div class="col-md-3"><img src="./img/DengEtAl_CVPR2021.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>3D AffordanceNet: A Benchmark for Visual Object Affordance Understanding</strong></span>
				<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_3D_AffordanceNet_A_Benchmark_for_Visual_Object_Affordance_Understanding_CVPR_2021_paper.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="https://andlollipopde.github.io/3D-AffordanceNet/#/" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2021/DengEtAl_CVPR21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Shengheng Deng# <b>Xun Xu#</b>, Chaozheng Wu, Ke Chen and Kui Jia<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2021</b>) </span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/CaiEtAl_CVPR2021.png" width="200" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Revisiting Superpixels for Active Learning in Semantic Segmentation with Realistic Annotation Costs</strong></span>
				<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cai_Revisiting_Superpixels_for_Active_Learning_in_Semantic_Segmentation_With_Realistic_CVPR_2021_paper.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="./Doc/Publication/2021/CaiEtAl_CVPR21_Supp.pdf"  target="_blank"><span class="label label-default">Supplementary</span></a>
				<a href="https://github.com/cailile/Revisiting-Superpixels-for-Active-Learning" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2020/CaiEtAl_CVPR21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Lile Cai, <b>Xun Xu</b>, Junhao Lieuw and Chuan Sheng Foo<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2021</b>)</span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/LuEtAl_ICLR2021.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>ARMOURED: Adversarially Robust MOdels using Unlabeled data by REgularizing Diversity</strong></span>
				<a href="https://openreview.net/forum?id=JoCR4h9O3Ew"  target="_blank"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2021/LuEtAl_ICLR21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Kangkang Lu, Cuong M Nguyen, <b>Xun Xu</b>, Kiran Chari, Yu Jing Goh and Chuan Sheng Foo<br>
					International Conference on Learning Representations (<b>ICLR 2021</b>)</span>
			</div>
		</div>
		<br>

		<div class="row">
			<div class="col-md-3"><img src="./img/CaiEtAl_TIP21.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Exploring Spatial Diversity for Region-based Active Learning</strong></span>
				<a href=""  target="./Doc/Publication/2021/CaiEtAl_TIP21.pdf"><span class="label label-default">PDF</span></a>
				<!-- <a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a> -->
				<a href="./Doc/Publication/2021/CaiEtAl_TIP21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Lile Cai, <b>Xun Xu</b>, Lining Zhang and Chuan Sheng Foo<br>
					IEEE Transactions on Image Processing (<b>TIP</b>), 2021</span>
			</div>
		</div>
		<br>


		<div class="row">
                        <div class="col-md-3"><img src="./img/ZhangEtAl_BMVC21.png" width="280" style="border-style: none">
                        </div>
                        <div class="col-md-9">
                                <span class="title"><strong>On Automatic Data Augmentation for 3DPoint Cloud Classification</strong></span>
                                <a href="https://www.bmvc2021-virtualconference.com/assets/papers/0911.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
                                <a href="https://github.com/RosettaWYzhang/AdaPC" target="_blank"><span class="label label-success" >ProjectPage</span></a>
                                <a href="./Doc/Publication/2021/ZhangEtAl_BMVC21.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
                                <br>
                                <span class="details">Wanyue Zhang, <b>Xun Xu*</b>, Fayao Liu, Le Zhang and Chuan Sheng Foo<br>
                                        British Machine Vision Conference (<b>BMVC 2021</b>)</span>
                        </div>
                </div>
                <br>


		

		<div class="row">
			<div class="col-md-3"><img src="./img/WuEtAl_ShapeSaliency.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Learning Category-level Shape Saliency via Deep Implicit Surface Networks</strong></span>
				<a href="https://arxiv.org/abs/2012.07290"  target="_blank"><span class="label label-default">PDF</span></a>
				<!--<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>-->
				<!--<a href="./Doc/Publication/2020/LuEtAl_ICLR2021.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>-->
				<br>
				<span class="details">Chaozheng Wu, Sun Lin, <b>Xun Xu</b> and Kui Jia<br>
					Preprint, 2021</span>
			</div>
		</div>
		<br>

		<h4>2020</h4>
		<div class="row">
			<div class="col-md-3"><img src="./img/JiangXZLZ_MMSP20.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>MultiANet: a Multi-Attention Network for DefocusBlur Detection</strong></span>
				<a href="./Doc/Publication/2020/JiangXZZ_MMSP20.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2020/JiangXZZ_MMSP20.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details">Zeyu Jiang, <b>Xun Xu</b>, Chao Zhang, Xiaoning Liu and Ce Zhu<br>
					IEEE International Workshop on Multimedia Signal Processing (<b>MMSP 2020</b>)</span>
			</div>

		</div>
		<br>

		
		<div class="row">
                        <div class="col-md-3"><img src="./img/XuL_CVPR20_Thumbnail.png" width="280" style="border-style: none">
                        </div>
                        <div class="col-md-9">
                                <span class="title"><strong>Weakly Supervised Semantic Point Cloud Segmentation: Towards 10 Fewer
Labels</strong></span>
                                <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Weakly_Supervised_Semantic_Point_Cloud_Segmentation_Towards_10x_Fewer_Labels_CVPR_2020_paper.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
                                <a href="https://github.com/alex-xun-xu/WeakSupPointCloudSeg" target="_blank"><span class="label label-success" >ProjectPage</span></a>
                                <a href="./Doc/Publication/2020/XuL_CVPR20.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
                                <br>
                                <span class="details"><b>Xun Xu</b> and Gim Hee Lee<br>
                                        IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2020</b>)</span>
                        </div>

                </div>
		<br>
		
		<h4>2019</h4>
		<div class="row">

			<div class="col-md-3"><img src="./img/XuCL_TPAMI19_Thumbnail.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>3D Rigid Motion Segmentation with Mixed and
Unknown Number of Models</strong></span>
				<a href="./Doc/Publication/2019/XuCL_TPAMI19.pdf"  target="_blank"><span class="label label-default">PDF</span></a>
				<a href="./ProjectPage/CVPR_18/index.html" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2019/XuCL_TPAMI19.bib"  target="_blank"><span class="label label-default">Bibtex</span></a>
				<br>
				<span class="details"><b>Xun Xu</b> Loong-Fah Cheong and Zhuwen Li<br>
					IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2019</span>
			</div>
		</div>
		<br>
		
		<div class="row">
		
			<div class="col-md-3"><img src="./img/ZLXZ_CVPR19.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> C3AE: Exploring the Limits of Compact Model for Age Estimation</strong></span>
				<a href="https://arxiv.org/abs/1904.05059"  target="_blank"><span class="label label-default">PDF</span></a><br>
				<span class="details">Chao Zhang, Shuaicheng Liu, <b>Xun Xu</b> and Ce Zhu<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2019</b>) </span>
			</div>
		</div>
		<br>

		<!-- <div class='row'>
			<div class="col-md-3"><img src="./img/XuCL_CVPR19_Thumbnail.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong> Learning for Multi-Model and Multi-Type Fitting </strong></span>
				<a href="https://arxiv.org/abs/1901.10254"  target="_blank"><span class="label label-default">ArXiv</span></a><br>
				<span class="details"><b>Xun Xu</b>, Loong-Fah Cheong and Zhuwen Li<br>
					ArXiv:1901.10254, 2019 </span>
			</div>
		</div> -->  
		
		<h4>2018</h4>
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuCL_CVPR18_Thumbnail.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Motion Segmentation by Exploiting Complementary Geometric Models </strong></span>
				<a href="./Doc/Publication/2018/XuCL_CVPR18.pdf"  target="_blank"><span class="label label-default">PDF</span></a> <a href="./ProjectPage/CVPR_18/index.html" target="_blank"><span class="label label-success" >ProjectPage</span></a> <a href="./Doc/Publication/2018/XuCL_CVPR18.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details"><b>Xun Xu</b>, Loong-Fah Cheong and Zhuwen Li<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR 2018</b>) </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/LinJCLX_ACCV18.png" width="280" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Robust Video Background Identification by Dominant Rigid Motion Estimation</strong></span>
				<a href="./Doc/Publication/2018/LinJCLX_ACCV2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/LinJCLX_ACCV2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details">Kaimo Lin, Nianjuan Jiang, Loong Fah Cheong, Jiangbo Lu and <b>Xun Xu</b><br>
				Asian Conference on Computer Vision (<b>ACCV 2018</b>) </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/ZhangZXXL_ICME18.png" width="190" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Image Ordinal Classification and Understanding: Grid Dropout with Mask Label</strong></span>
				<a href="./Doc/Publication/2018/ZhangZXXL_ICME2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/ZhangZXXL_ICME2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a>  <b>[Oral Presentation]</b><br>
				<span class="details">Chao Zhang, Ce Zhu, Jimin Xiao, <b>Xun Xu</b> and Yipeng Liu<br>
				IEEE Conference on Multimedia and Expo (<b>ICME 2018</b>) </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/ZhangZXXLT_SPIC18.png" width="200" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Visual aesthetic understanding: Sample-specific aesthetic classification and deep activation map visualization</strong></span>
				<a href="./Doc/Publication/2018/ZhangZXXLT_SPIC2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/ZhangZXXLT_SPIC2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details">Chao Zhang, Ce Zhu, <b>Xun Xu</b>, Yipeng Liu, Jimin Xiao and Tammam Tillo<br>
				Signal Processing: Image Communication (<b>SPIG</b>), 2018 </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/ZhangXZ_EL18.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Image ordinal classification with deep multi-view learning</strong></span>
				<a href="./Doc/Publication/2018/ZhangXZ_EL2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/ZhangXZ_EL2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details">Chao Zhang,  <b>Xun Xu</b> and Ce Zhu<br>
				Electronic Letters, 2018 </span>
			</div>
		</div>
		
		
		<h4>2017</h4>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_IJCV17.png" width="260" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Transductive Zero-Shot Action Recognition by Word-Vector Embedding</strong></span>
				<a href="./Doc/Publication/2017/XuHG_IJCV2017.pdf"><span class="label label-default">PDF</span></a> <a href="./ProjectPage/IJCV_17/Readme.txt" target="_blank"><span class="label label-success" >Data</span></a> <a href="./Doc/Publication/2017/XuHG_IJCV17.txt" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				International Journal of Computer Vision (<b>IJCV</b>), 2017 </span>
			</div>
		</div>
		<br>
		
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_TCSVT15.png" width="240" style="border-style: none">
			</div>
			
		
			<div class="col-md-9">
				<span class='title'><strong>Discovery of Shared Semantic Spaces for Multi-Scene Video Query and Summarization</strong></span> <a href="./Doc/Publication/2015/XuHG_TCSVT2015.pdf"><span class="label label-default">PDF</span></a>  <a href="./Doc/Publication/2015/XuHG_TCSVT2015_Supp.pdf"><span class="label label-default">Supplementary</span></a>  <a href="./ProjectPage/TCSVT_15/data/MultiScene.pdf"><span class="label label-success">Slides</a> <a href="./ProjectPage/TCSVT_15/index.html"><span class="label label-success">Project Page</span></a> <a href="./Doc/Publication/2017/XuHG_TCSVT17.txt" target="_blank"><span class="label label-default">Bibtex</span></a> <b></b> <br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2017</span>
			</div>
		</div>
		<br>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuGH_ZSLCrowdBehaviour17.png" width="260" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Zero-Shot Crowd Behaviour Recognition</strong></span>
				<a href="./Doc/Publication/2017/XuGH_ZSLCrowdBehaviour2017.pdf"><span class="label label-default">PDF</span></a> <br>
				<span class="details"><b>Xun Xu</b>, Shaogang Gong and Timothy Hospedales<br>
				In Murino, Shah, Cristani, Savarese (Eds.), <a href="https://www.elsevier.com/books/group-and-crowd-behavior-for-computer-vision/murino/978-0-12-809276-7">Group and Crowd Behaviour Understanding in Computer Vision </a>, Elsevier, April 2017. </span>
			</div>
		</div>
		
		<br>
		
		
		<h4>2016</h4>
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_ECCV16.png" width="260" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>Multi-Task Zero-Shot Action Recognition with Prioritised Data Augmentation</strong></span>
				<a href="./Doc/Publication/2016/XuHG_ECCV2016.pdf"><span class="label label-default">PDF</span></a> <a href="./ProjectPage/IJCV_17/Readme.txt" target="_blank"><span class="label label-success" >Data</span></a> <a href="./Doc/Publication/2016/XuHG_ECCV16.txt" target="_blank"><span class="label label-default">Bibtex</span></a> <br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				European Conference on Computer Vision (<b>ECCV 2016</b>) </span>
			</div>
		</div>
		
		<h4>2015</h4>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_ICIP15.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>Semantic Embedding Space for Zero Shot Action Recognition</strong></span>
				<a href="./Doc/Publication/2015/XuHG_ICIP2015.pdf"><span class="label label-default">PDF</span></a> <a href="http://www.eecs.qmul.ac.uk/~xx302/Doc/Publication/2015/XuHG_ICIP2015_Slides.pptx"><span class="label label-success">Slides</span></a> <a href="./ProjectPage/ICIP_15/Demo.tar.gz"><span class="label label-success">Demo</span></a> <a href="./ProjectPage/ICIP_15/XuHG_ICIP15.bib"><span class="label label-default">Bibtex</span></a> <b>[ recognized as top 10% papers]</b> <br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				International Conference on Image Processing (<b>ICIP 2015</b>) </span>
			</div>
		</div>
		
		<h4>2013</h4>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuGH_ACMMM_ARTEMIS13.png" width="230" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>Cross-Domain Traffic Scene Understanding by Motion Model Transfer</strong></span> 
				<a href="./Doc/Publication/2013/XuGH_ACMMM_ARTEMIS2013.pdf"><span clsudo nvidia-smi -pm 1
ass="label label-default">PDF</span></a>
				<a href="./Doc/Publication/2013/Artemix13_XuGH_Demo_ver1.0.7z"><span class="label label-default">Code</span></a> <a href="./Doc/Publication/2013/XuGH_ACMMM_ARTEMIS2013.bib"><span class="label label-default">Bibtex</span></a> </br>
				<span class="details"><b>Xun Xu</b>, Shaogang Gong and Timothy Hospedales</br>
				ACM International Conference on Multimedia,
					Workshop on Analysis and Retrieval of Tracked Events and Motion in Imagery Streams</i>, 2013 </span>
			</div>
		</div>
		
	</section>

</div>

<br>
<br>
<br>




<div class="container">
	<p class="pull-right"><a href="#HOME">Back to top</a></p>
	<p><small>Updated Jan 2025</small></p>
	<!-- <p><small>Page created using <a href="http://twitter.github.com/bootstrap" target="_blank">bootstrap</a></small></p> -->
</div>

</body>
</html>
