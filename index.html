<!DOCTYPE html>
<html lang="en">
<head>
  <title>Xun Xu, PhD</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="Xun Xu, Alex Xun Xu, Zero-Shot Learning, Transfer Learning, Action Recognition, Traffic Analysis, Anomaly Detection, Motion Segmentation, Deep Learning, Topic Model, Computer Vision, Machine Learning">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
</head>
<body>

<nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="#">Dr. Xun Xu</a>
    </div>
    <ul class="nav navbar-nav">
      <li class="active"><a href="#HOME">Home</a></li>
      <li><a href="#ABOUTME">About</a></li>
      <li><a href="#PUBLICATION">Publication</a></li>
    </ul>
  </div>
</nav>

<div class="container">

	<section id="HOME">
			<div class="page-header">
				<h2>Xun Xu<mdall> PhD B.Eng. </mdall></h2>
			</div>
			<div class="row">
			
				<div class="col-md-2">
					<div class="thumbnail">
						<img src="./img/XuXun_Corp2.jpg" class="img-rounded">
					</div>
				</div>
				
				<div class="col-md-3">
					<p>
						<strong>Scientist</strong>
					</p>
					<address>
						<a href="https://www.a-star.edu.sg/i2r">Institute for Infocomm Research (I2R)</a><br/>
						<a href="https://www.a-star.edu.sg/">A-STAR</a><br/>
						Level 10 Connexis (North Tower) </br>
						Singapore 138632 <br>
						E-mail: xux AT i2r.a-star.edu.sg
						<a href='https://scholar.google.com.sg/citations?user=pi0SGQUAAAAJ&hl=en'><span class='label label-primary'>Google Scholar</span></a>
						<a href='https://github.com/alex-xun-xu'><span class='label label-default'>GitHub</span></a>
						<a href='https://www.linkedin.com/in/xu-xun/'><span class='label label-info'>LinkedIn</span></a>
					</address>
				</div>
				
				<div class="col-md-7">
					<p>
						I am currently a scientist with the Institute for Infocomm Research (I2R), A-STAR. Prior to that, I was a Research Fellow working with <a href="https://sites.google.com/site/gimheelee/">Assist Prof. Lee Gim Hee</a> in the Computer Vision and Robotic Perception (CVRP) Lab of School of Computing, <a href="http://nus.edu.sg/">Natinoal University of Singapore</a> (NUS). I also worked with <a href="https://www.ece.nus.edu.sg/stfpage/eleclf/">Prof. Cheong Loong Fah</a> in Visual Interactive Media Lab of NUS from Sep 2016 to Mar 2019.
						I received a PhD degree from <a href="http://vision.eecs.qmul.ac.uk">Computer Vision Group</a> in the School of Electronic Engineering and Computer Science at <a href="http://www.qmul.ac.uk">Queen Mary, University of London</a> (QMUL), jointly supervised by <a href="http://www.eecs.qmul.ac.uk/~sgg/">Prof. Shaogang Gong</a> and <a href="http://www.eecs.qmul.ac.uk/~txiang/">Dr. Tao Xiang</a>. I was also working closely with <a href="http://homepages.inf.ed.ac.uk/thospeda/">Dr. Timothy Hospedales </a>.
					</p>
					<p>
						Before joining the Computer Vision Group in QMUL I received my B.Eng in Automation from <a href="http://www.scu.edu.cn">Sichuan University</a> and then had spent 2 years in <a href="#">3D Vision Lab</a> at Sichuan University supervised by <a href="mailto:yushengliu866@hotmail.com">Prof. Yusheng Liu</a> and <a href="http://www.linkedin.com/pub/kai-liu/16/285/a94">Prof. Kai Liu</a>.
					</p>
					<p>	My research interests include point cloud analysis, motion segmentation, zero-shot learning and surveillance scene understanding.
					</p>
				</div>
			</div>
	</section>
</div>


<div class='container'>

	<section id='NEWS'>
			<div class="page-header">
				<h3>NEWS<mdall></mdall></h3>
			</div>
			<div class="row">
				<div class="col-md-12">
					<h4></h4>
					Jul 2021: <b>PostDoc Fellowship Opportunities</b><br>
					<li> You will have a chance to carry out postdoc research in A*STAR with competitive fellowship if you are ASEAN citizenship. More details can be found at <a href="https://snas.org.sg/aseanfellowship" target="_blank">check your availibity</a>. Please contact if you are qualified and interested. Deadline is 30 Nov 2021.
					<h4></h4>
					May 2021: <b>A*STAR CDA Project "Exploiting Unlabeled Data, Cheaper Labels and Efficient Annotation for 3D 
Point Cloud Deep Learning" (EUDEA)</b><br>
					<ul>
					<li> My project on exploring label-efficient learning on 3D point cloud data started from Apr. 2021.<br>
					<li> We will be looking into improving the efficiency of 3D point cloud learning from several perspectives.<br>
					</ul>
				</div>
			
				<div class="col-md-12">
					<h4></h4>
					Nov 2020: <b>PhD/Postgraduate/Undergraduate Scholarship Opportunities</b><br>
					<ul>
					<li> We are looking for highly motivated international students who wish to do PhD in A*STAR, NUS, NTU, SUTD. We provide <b>full scholarship under the SINGA program</b> (<a href='https://www.a-star.edu.sg/Scholarships/for-graduate-studies/singapore-international-graduate-award-singa' target="_blank">check your eligibility</a>).<br>
					<li> We also welcome international full-time PhD students who wish to do research attachment (1-2 years research with A*STAR). <b>Full scholarship under the ARAP program</b> will be provided during the attachment period in Singapore (<a href='https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme-(arap)' target="_blank">Check your eligibility</a>)<br>
					<li> We provide scholarship for talented postgraduate/undergraduate students who wish to do research attachment (2-6 months with A*STAR) or prepare to apply for PhD under the SIPGA program (<a href='https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies/singapore-international-pre-graduate-award-(sipga)' target="_blank">Check your availability</a>).
					</ul>
				</div>
			</div>
		</section>
	
	</section>

</div>


<div class='container'>

	<section id='ABOUTME'>
			<div class="page-header">
				<h3>About Me<mdall></mdall></h3>
			</div>
			<div class="row">
				<div class="col-md-4">
					<h4>Education Background</h4>
					<ul>
						<li>PhD in Computer Science, Queen Mary University of London, 2016<br>
							Thesis: <a href="https://www.dropbox.com/s/zc4m6yvjh49t6wu/Xu_Thesis_Final.pdf?dl=0">Semantic Spaces for Video Analysis of Behaviour</a> <br>
							Supervisors: Prof. Shaogang Gong and Dr. Tao Xiang
						<li>M.Sc in Control Theory and Engineering, Sichuan University, 2012<br>
							Supervisor: Prof. Yusheng Liu
						<li>B.Eng in Automation, Sichuan University, 2010<br>
							Advisor: Prof. Yong Lei
						
					</ul>
				</div>
				<div class="col-md-4">
					<h4>Professional Experience</h4>
					<ul>
						<li>Scientist with I2R, A-STAR, Singpaore<br>
							2019.12-Now<br>
						<li>Research Fellow in SoC, National University of Singapore<br>
							2019.4-2019.12<br>
							Supervisors: Prof. Gim Hee Lee
						<li>Research Fellow in ECE, National University of Singapore<br>
							2016.9-2019.3<br>
							Project: Dynamic Vision for Actions <br>
							Supervisors: Prof. Loong-Fah Cheong
					</ul>
				</div>
				
				<div class="col-md-4">
					<h4>Academic Services</h4>
						<h5><b>Member</b></h5>
						<ul>
							<li>IEEE Senior Member</li>
						</ul>
						<h5><b>Journal Reviewer</b></h5>
						<ul>
							<li> International Journal of Computer Vision (IJCV) </li>
							<li> IEEE Transactions on Image Processing (TIP)</li>
							<li> ACM Transactions on Knowledge Discovery from Data (TKDD)</li>
							<li> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
							<li> IEEE Transactions on Cybernetics </li>
							<li> IEEE Access</li>
							<li> GeoInformatica - Springer</li>
							<li> Neural Computing & Applications - Springer</li>
							<li> IET Computer Vision</li>
						</ul>
						<h5><b>Conference Reviewer</b></h5>
						<ul>
							<li> NeurIPS </li>
							<li> ICML </li>
							<li> CVPR</li>
							<li> ECCV </li>
							<li> ICCV </li>
							<li> ACM MM</li>
							<li> IROS </li>
							<li> BMVC</li>
						</ul>
				</div>
			</div>
		</section>
	
	</section>

</div>


<div class='container'>

	<section id='PUBLICATION'>
	
		<div class="page-header">
			<h3>Publication<mdall></mdall></h3>
		</div>
			
		My <a href="https://scholar.google.com.sg/citations?user=pi0SGQUAAAAJ&hl=en">Google Scholar Profile</a>
		<h4>2021</h4>
		<div class="row">
			<div class="col-md-3"><img src="./img/LuEtAl_ICLR2021.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>ARMOURED: Adversarially Robust MOdels using Unlabeled data by REgularizing Diversity</strong></span>
				<a href="https://openreview.net/forum?id=JoCR4h9O3Ew"  target="_blank"><span class="label label-default">PDF</span></a></a>
				<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2020/LuEtAl_ICLR2021.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Kangkang Lu, Cuong M Nguyen, <b>Xun Xu</b>, Kiran Chari, Yu Jing Goh and Chuan Sheng Foo<br>
					International Conference on Learning Representations (<b>ICLR</b>), 2021</span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/XuEtAl_TCSVT2021.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Learning Clustering for Motion Segmentation</strong></span>
				<a href="./Doc/Publication/2021/XuEtAl_TCSVT21.pdf"  target="_blank"><span class="label label-default">PDF</span></a></a>
				<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2020/XuEtAl_TCSVT2021.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details"><b>Xun Xu</b>, Loong-Fah Cheong, Zhuwen Li, Le Zhang and Ce Zhu<br>
					IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2021</span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/DengEtAl_CVPR2021.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>3D AffordanceNet: A Benchmark for Visual Object Affordance Understanding</strong></span>
				<a href="https://arxiv.org/pdf/2103.16397.pdf"  target="_blank"><span class="label label-default">PDF</span></a></a>
				<a href="https://andlollipopde.github.io/3D-AffordanceNet/#/" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2020/DengEtAl_CVPR2021.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Shengheng Deng, <b>Xun Xu</b>, Chaozheng Wu, Ke Chen and Kui Jia<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021</span>
			</div>
		</div>
		<br>


		<div class="row">
			<div class="col-md-3"><img src="./img/CaiEtAl_CVPR2021.png" width="200" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>Revisiting Superpixels for Active Learning in Semantic Segmentation with Realistic Annotation Costs</strong></span>
				<a href="./Doc/Publication/2021/CaiEtAl_CVPR21.pdf"  target="_blank"><span class="label label-default">PDF</span></a></a>
				<a href="./Doc/Publication/2021/CaiEtAl_CVPR21_Supp.pdf"  target="_blank"><span class="label label-default">Supplementary</span></a></a>
				<a href="" target=""><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2020/CaiEtAl_CVPR2021.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Lile Cai, <b>Xun Xu</b>, Junhao Lieuw and Chuan Sheng Foo<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021</span>
			</div>
		</div>
		<br>

		<h4>2020</h4>
		<div class="row">
			<div class="col-md-3"><img src="./img/JiangXZLZ_MMSP20.png" width="280" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong>MultiANet: a Multi-Attention Network for DefocusBlur Detection</strong></span>
				<a href="./Doc/Publication/2020/JiangXZZ_MMSP20.pdf"  target="_blank"><span class="label label-default">PDF</span></a></a>
				<a href="" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2020/JiangXZZ_MMSP20.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details">Zeyu Jiang, <b>Xun Xu</b>, Chao Zhang, Xiaoning Liu and Ce Zhu<br>
					IEEE International Workshop on Multimedia Signal Processing (<b>MMSP</b>), 2020</span>
			</div>

		</div>
		<br>

		
		<div class="row">
                        <div class="col-md-3"><img src="./img/XuL_CVPR20_Thumbnail.png" width="280" style="border-style: none">
                        </div>
                        <div class="col-md-9">
                                <span class="title"><strong>Weakly Supervised Semantic Point Cloud Segmentation: Towards 10× Fewer
Labels</strong></span>
                                <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Weakly_Supervised_Semantic_Point_Cloud_Segmentation_Towards_10x_Fewer_Labels_CVPR_2020_paper.pdf"  target="_blank"><span class="label label-default">PDF</span></a></a>
                                <a href="https://github.com/alex-xun-xu/WeakSupPointCloudSeg" target="_blank"><span class="label label-success" >ProjectPage</span></a>
                                <a href="./Doc/Publication/2020/XuL_CVPR20.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
                                <br>
                                <span class="details"><b>Xun Xu</b> and Gim Hee Lee<br>
                                        IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020</span>
                        </div>

                </div>
		<br>
		
		<h4>2019</h4>
		<div class="row">

			<div class="col-md-3"><img src="./img/XuCL_TPAMI19_Thumbnail.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>3D Rigid Motion Segmentation with Mixed and
Unknown Number of Models</strong></span>
				<a href="./Doc/Publication/2019/XuCL_TPAMI19.pdf"  target="_blank"><span class="label label-default">PDF</span></a></a>
				<a href="./ProjectPage/CVPR_18/index.html" target="_blank"><span class="label label-success" >ProjectPage</span></a>
				<a href="./Doc/Publication/2019/XuCL_TPAMI19.bib"  target="_blank"><span class="label label-default">Bibtex</span></a></a>
				<br>
				<span class="details"><b>Xun Xu</b>， Loong-Fah Cheong and Zhuwen Li<br>
					IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2019</span>
			</div>
		</div>
		<br>
		
		<div class="row">
		
			<div class="col-md-3"><img src="./img/ZLXZ_CVPR19.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> C3AE: Exploring the Limits of Compact Model for Age Estimation</strong></span>
				<a href="https://arxiv.org/abs/1904.05059"  target="_blank"><span class="label label-default">PDF</span></a></a><br>
				<span class="details">Chao Zhang, Shuaicheng Liu, <b>Xun Xu</b> and Ce Zhu<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019 </span>
			</div>
		</div>
		<br>

		<div class='row'>
			<div class="col-md-3"><img src="./img/XuCL_CVPR19_Thumbnail.png" width="230" style="border-style: none">
			</div>
			<div class="col-md-9">
				<span class="title"><strong> Learning for Multi-Model and Multi-Type Fitting </strong></span>
				<a href="https://arxiv.org/abs/1901.10254"  target="_blank"><span class="label label-default">ArXiv</span></a><br>
				<span class="details"><b>Xun Xu</b>, Loong-Fah Cheong and Zhuwen Li<br>
					ArXiv:1901.10254, 2019 </span>
			</div>
		</div>
		
		<h4>2018</h4>
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuCL_CVPR18_Thumbnail.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Motion Segmentation by Exploiting Complementary Geometric Models </strong></span>
				<a href="./Doc/Publication/2018/XuCL_CVPR18.pdf"  target="_blank"><span class="label label-default">PDF</span></a> <a href="./ProjectPage/CVPR_18/index.html" target="_blank"><span class="label label-success" >ProjectPage</span></a> <a href="./Doc/Publication/2018/XuCL_CVPR18.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details"><b>Xun Xu</b>, Loong-Fah Cheong and Zhuwen Li<br>
					IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2018 </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/LinJCLX_ACCV18.png" width="280" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Robust Video Background Identification by Dominant Rigid Motion Estimation</strong></span>
				<a href="./Doc/Publication/2018/LinJCLX_ACCV2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/LinJCLX_ACCV2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details">Kaimo Lin, Nianjuan Jiang, Loong Fah Cheong, Jiangbo Lu and <b>Xun Xu</b><br>
				Asian Conference on Computer Vision (<b>ACCV</b>), 2018 </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/ZhangZXXL_ICME18.png" width="190" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Image Ordinal Classification and Understanding: Grid Dropout with Mask Label</strong></span>
				<a href="./Doc/Publication/2018/ZhangZXXL_ICME2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/ZhangZXXL_ICME2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a>  <b>[Oral Presentation]</b><br>
				<span class="details">Chao Zhang, Ce Zhu, Jimin Xiao, <b>Xun Xu</b> and Yipeng Liu<br>
				IEEE Conference on Multimedia and Expo (<b>ICME</b>), 2018 </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/ZhangZXXLT_SPIC18.png" width="200" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Visual aesthetic understanding: Sample-specific aesthetic classification and deep activation map visualization</strong></span>
				<a href="./Doc/Publication/2018/ZhangZXXLT_SPIC2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/ZhangZXXLT_SPIC2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details">Chao Zhang, Ce Zhu, <b>Xun Xu</b>, Yipeng Liu, Jimin Xiao and Tammam Tillo<br>
				Signal Processing: Image Communication, 2018 </span>
			</div>
		</div>
		<br>
		
		<div class='row'>
			<div class="col-md-3"><img src="./img/ZhangXZ_EL18.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Image ordinal classification with deep multi-view learning</strong></span>
				<a href="./Doc/Publication/2018/ZhangXZ_EL2018.pdf" target="_blank"><span class="label label-default">PDF</span></a> <a href="./Doc/Publication/2018/ZhangXZ_EL2018.bib" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details">Chao Zhang,  <b>Xun Xu</b> and Ce Zhu<br>
				Electronic Letters, 2018 </span>
			</div>
		</div>
		
		
		<h4>2017</h4>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_IJCV17.png" width="260" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Transductive Zero-Shot Action Recognition by Word-Vector Embedding</strong></span>
				<a href="./Doc/Publication/2017/XuHG_IJCV2017.pdf"><span class="label label-default">PDF</span></a> <a href="./ProjectPage/IJCV_17/Readme.txt" target="_blank"><span class="label label-success" >Data</span></a> <a href="./Doc/Publication/2017/XuHG_IJCV17.txt" target="_blank"><span class="label label-default">Bibtex</span></a><br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				International Journal of Computer Vision (<b>IJCV</b>), 2017 </span>
			</div>
		</div>
		<br>
		
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_TCSVT15.png" width="240" style="border-style: none">
			</div>
			
		
			<div class="col-md-9">
				<span class='title'><strong>Discovery of Shared Semantic Spaces for Multi-Scene Video Query and Summarization</strong></span> <a href="./Doc/Publication/2015/XuHG_TCSVT2015.pdf"><span class="label label-default">PDF</span></a>  <a href="./Doc/Publication/2015/XuHG_TCSVT2015_Supp.pdf"><span class="label label-default">Supplementary</span></a>  <a href="./ProjectPage/TCSVT_15/data/MultiScene.pdf"><span class="label label-success">Slides</a> <a href="./ProjectPage/TCSVT_15/index.html"><span class="label label-success">Project Page</span></a> <a href="./Doc/Publication/2017/XuHG_TCSVT17.txt" target="_blank"><span class="label label-default">Bibtex</span></a> <b></b> <br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2017</span>
			</div>
		</div>
		<br>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuGH_ZSLCrowdBehaviour17.png" width="260" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong> Zero-Shot Crowd Behaviour Recognition</strong></span>
				<a href="./Doc/Publication/2017/XuGH_ZSLCrowdBehaviour2017.pdf"><span class="label label-default">PDF</span></a> <br>
				<span class="details"><b>Xun Xu</b>, Shaogang Gong and Timothy Hospedales<br>
				In Murino, Shah, Cristani, Savarese (Eds.), <a href="https://www.elsevier.com/books/group-and-crowd-behavior-for-computer-vision/murino/978-0-12-809276-7">Group and Crowd Behaviour Understanding in Computer Vision </a>, Elsevier, April 2017. </span>
			</div>
		</div>
		
		<br>
		
		
		<h4>2016</h4>
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_ECCV16.png" width="260" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>Multi-Task Zero-Shot Action Recognition with Prioritised Data Augmentation</strong></span>
				<a href="./Doc/Publication/2016/XuHG_ECCV2016.pdf"><span class="label label-default">PDF</span></a> <a href="./ProjectPage/IJCV_17/Readme.txt" target="_blank"><span class="label label-success" >Data</span></a> <a href="./Doc/Publication/2016/XuHG_ECCV16.txt" target="_blank"><span class="label label-default">Bibtex</span></a> <br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				In Proc. <i>European Conference on Computer Vision (<b>ECCV</b>)</i>, Amsterdam, The Netherlands, October 2016. </span>
			</div>
		</div>
		
		<h4>2015</h4>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuHG_ICIP15.png" width="220" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>Semantic Embedding Space for Zero ­Shot Action Recognition</strong></span>
				<a href="./Doc/Publication/2015/XuHG_ICIP2015.pdf"><span class="label label-default">PDF</span></a> <a href="http://www.eecs.qmul.ac.uk/~xx302/Doc/Publication/2015/XuHG_ICIP2015_Slides.pptx"><span class="label label-success">Slides</span></a> <a href="./ProjectPage/ICIP_15/Demo.tar.gz"><span class="label label-success">Demo</span></a> <a href="./ProjectPage/ICIP_15/XuHG_ICIP15.bib"><span class="label label-default">Bibtex</span></a> <b>[★ recognized as top 10% papers]</b> <br>
				<span class="details"><b>Xun Xu</b>, Timothy Hospedales and Shaogang Gong<br>
				In Proc. <i>International Conference on Image Processing (<b>ICIP</b>)</i>, Quebec, Canada, September, 2015 </span>
			</div>
		</div>
		
		<h4>2013</h4>
		
		<div class='row'>
		
			<div class="col-md-3"><img src="./img/XuGH_ACMMM_ARTEMIS13.png" width="230" style="border-style: none">
			</div>
			
			<div class="col-md-9">
				<span class="title"><strong>Cross-Domain Traffic Scene Understanding by Motion Model Transfer</strong></span> 
				<a href="./Doc/Publication/2013/XuGH_ACMMM_ARTEMIS2013.pdf"><span class="label label-default">PDF</span></a>
				<a href="./Doc/Publication/2013/Artemix13_XuGH_Demo_ver1.0.7z"><span class="label label-default">Code</span></a> <a href="./Doc/Publication/2013/XuGH_ACMMM_ARTEMIS2013.bib"><span class="label label-default">Bibtex</span></a> </br>
				<span class="details"><b>Xun Xu</b>, Shaogang Gong and Timothy Hospedales</br>
				In Proc. <i>ACM International Conference on Multimedia</i>,<i>
				Workshop on Analysis and Retrieval of Tracked Events and Motion in Imagery Streams</i>, Barcelona, Spain, October, 2013
			</div>
		</div>
		
	</section>

</div>

<br>
<br>
<br>

<div class="container">
	<p class="pull-right"><a href="#HOME">Back to top</a></p>
	<p><small>Updated Jul 2021</small></p>
	<!-- <p><small>Page created using <a href="http://twitter.github.com/bootstrap" target="_blank">bootstrap</a></small></p> -->
</div>

</body>
</html>
